---
title: "Behavioral Analyses"
author: "baf44"
date: "1/23/2023"
output: html_document
editor_options: 
  chunk_output_type: console
---

Code to plot and analyze in-scanner behavioral data (% wanting).

This code uses the following derivative files:

(1) BIDS/derivatives/preprocessed/task-foodcue_summary.tsv
    This contains long summary data (by block) for behavior during the foodcue task
    This was generated by BIDS/code/foodcue_proc/p0_getbehavioral.py
(2) BIDS/derivatives/preprocessed/fmriprep/task-foodcue_byrun-censorsummary_fd-0.9.tsv
    This contains censor information (due to motion) for the foodcue task by run for each subject 
    This was generated by BIDS/code/afni/foodcue_proc/p2_create_censor_files.py
(3) BIDS/derivatives/analyses/foodcue-paper1/level2/index_all_fd-0.9_b20_3runs.txt
    This contains a list of subjects included in fmri analyses 
    This was generated by BIDS/code/afni/groupanalyses_paper1/prep_index_byrun.py

# Setup

```{r imports, include=FALSE}
library(lme4)
library(lmerTest) # need this to get p-values with anova()
library(plyr)
library(maditr)
library(ggplot2)
library(rstatix)
library(dplyr)
library(psych)
library(emmeans)
library(stringr)
library(ggsignif)

#### import BIDS derivatives to use in analyses ####

# import behavioral data
beh_all <- read.delim("BIDS/derivatives/preprocessed/beh/task-foodcue_summary.tsv") 

# import index file that specifies children included in analyses (can also source("R/data_org.R") to import
index_wide <- read.table("BIDS//derivatives/analyses/foodcue-paper1/level2/index_all_fd-0.9_b20_3runs.txt", quote="\"", comment.char="")
index <- as.data.frame(t(index_wide)) # transpose index_wide to long dataframes
names(index) <- "id" # add column name

#censor sum database (can also source("R/data_org.R") to import
censor_sum <- read.delim("BIDS/derivatives/preprocessed/fmriprep/task-foodcue_byrun-censorsummary_fd-0.9.tsv")
names(censor_sum)[names(censor_sum) == 'sub'] <- 'id'

```

Prepare dataframe of in-scanner behavior (p_want)

```{r prep beh dataset}
# remove condition letter (A-F) from block_proc 
beh_all$block_proc <- substring(beh_all$block_proc, 2)

# Add portion_size and cue-type columns
beh_all$portion_size <- ifelse(grepl("Large", beh_all$cond), "Larger", "Smaller")
beh_all$energy_density <- ifelse(grepl("High", beh_all$cond), "HighED", 
                       ifelse(grepl("Low", beh_all$cond), "LowED", "NA"))
beh_all$cue_type <- ifelse(grepl("High", beh_all$cond), "food", 
                       ifelse(grepl("Low", beh_all$cond), "food", "office"))
beh_all$category <- ifelse(grepl("High", beh_all$cond), "HighED", 
                       ifelse(grepl("Low", beh_all$cond), "LowED", "Office"))


# subset to children included for non-parametric fmri analyses
beh <- setDT(beh_all)[id %chin% index$id]

# create food-only dataframe by removing office conditions
beh_food<-beh[!(beh$cue_type=="office"),]

```

# Behavioral analyses

The following code analyses p_want () by cue type/ED and amount and generates corresponding plots.
Behavior is assessed for all subjects included in non-parametric analyses (n=61).

Behavioral analyses:
``` {r p_want lmer analyses}

# remove NAs -- not needed to run analyses, but helpful for predicting values to plot results
beh_clean <- beh[!is.na(beh$p_want_of_resp),]
beh_food_clean<-beh_food[!is.na(beh_food$p_want_of_resp),]

# calculate percentage from proportion
beh_clean$percent_want_of_resp <- beh_clean$p_want_of_resp*100
beh_food_clean$percent_want_of_resp <- beh_food_clean$p_want_of_resp*100

#### ANALYSES ####

beh_clean$run <- as.integer(beh_clean$run)
beh_food_clean$run <- as.integer(beh_food_clean$run)

# portion size (large, small) x cue type (food, office)
lmer_prop_want_cuetype = lmer(p_want_of_resp ~ cue_type*portion_size + run + (1 | id), data = beh_clean)
lmer_perc_want_cuetype = lmer(percent_want_of_resp ~ cue_type*portion_size + run + (1 | id), data = beh_clean)

anova(lmer_prop_want_cuetype) # main effect of cue type
anova(lmer_perc_want_cuetype) # main effect of cue type


# portion size (large, small) x food-cue type (high, low)
lmer_prop_want_ED = lmer(p_want_of_resp ~ energy_density*portion_size + run + (1 | id), data = beh_food_clean)
lmer_perc_want_ED = lmer(percent_want_of_resp ~ energy_density*portion_size + run + (1 | id), data = beh_food_clean)
anova(lmer_prop_want_ED)

#### EMMS ####

##  get estimated marginal means and SEs by conditions showing effect (cue type and ED)

#emmeans(lmer_prop_want_cuetype, specs = pairwise ~cue_type|portion_size, type = "response")
emmeans(lmer_prop_want_cuetype, specs = pairwise ~cue_type, type = "response")
emmeans(lmer_perc_want_cuetype, specs = pairwise ~cue_type, type = "response")

#emmeans(lmer_prop_want_ED, specs = pairwise ~energy_density|portion_size, type = "response")
emmeans(lmer_prop_want_ED, specs = pairwise ~energy_density, type = "response")

```


``` {r check assumptions }

##  assess assumptions ##
# residual plots
plot(lmer_prop_want_cuetype)
plot(lmer_prop_want_ED)

# see threads on residual plot that looks similar to this:
# https://stats.stackexchange.com/questions/120751/not-sure-about-the-interpretation-of-this-residual-plot
# https://stats.stackexchange.com/questions/524078/assumptions-of-linearity-and-homoskedasticity-when-the-dv-is-a-likert-scale-ho 

qqnorm(resid(lmer_prop_want_cuetype))
qqline(resid(lmer_prop_want_cuetype))
qqnorm(resid(lmer_prop_want_ED))
qqline(resid(lmer_prop_want_ED))


```

Figure 1:
``` {r p_want plots}

### plot predicted values (marginal effects) with sjPlot
# type = "int" plots marginal effects of interaction terms in model
install.packages("sjPlot")

plot_model(lmer_prop_want_cuetype, type = "int", ci.lvl = 0.95) + ylim(0, 1)
plot_model(lmer_prop_want_ED, type = "int", ci.lvl = 0.95) + ylim(0, 1)

#### Violin plots

# get adjusted response after adjusting for covariates in model 
beh_clean$predict_lmer_prop_want_cuetype <- predict(lmer_prop_want_cuetype, type="response")
beh_food_clean$predict_lmer_prop_want_ED <- predict(lmer_prop_want_ED, type="response")

beh_clean$predict_lmer_perc_want_cuetype <- predict(lmer_perc_want_cuetype, type="response")
beh_food_clean$predict_lmer_perc_want_ED <- predict(lmer_perc_want_ED, type="response")


#### VIOLIN PLOTS with ggplot####

# Amount (large, small) x cue (food, office)
plot_cuetype <- ggplot(beh_clean, aes(x=cue_type, y=predict_lmer_perc_want_cuetype, fill = portion_size)) +
  theme_bw() +
  geom_violin(trim=FALSE)+
  geom_signif(comparisons = list(c("food","office")), y_position = 120,
              map_signif_level = TRUE)+
  geom_boxplot(aes(group = interaction(cue_type, portion_size)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(x="Cue Type",
       y = "Adjusted %want") +
  theme(legend.title = element_blank()) +
  theme(axis.text=element_text(size=12, color = "black"), axis.title=element_text(size=14,face="bold")) + 
  ylim(-5, 125) + 
  scale_x_discrete(labels = c("food" = "Food",
                              "office" = "Office Supplies"))

plot_cuetype

# # Food amount (large, small) x ED (high, low)
plot_ED <- ggplot(beh_food_clean, aes(x=energy_density, y=predict_lmer_perc_want_ED, fill = portion_size)) +
  theme_bw() +
  geom_violin(trim=FALSE)+
  geom_signif(comparisons = list(c("HighED","LowED")), y_position = 120,
              map_signif_level = TRUE) +
  geom_boxplot(aes(group = interaction(energy_density, portion_size)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(x="Energy Density",
       y = "Adjusted %want") +
  theme(legend.title = element_blank()) +
  theme(axis.text=element_text(size=12, color = "black"), axis.title=element_text(size=14,face="bold")) + 
  ylim(-5, 125) +
  scale_x_discrete(labels = c("HighED" = "Higher",
                              "LowED" = "Lower"))

plot_ED


```

# Prepare for parametric analyses

The follow chunk is used to determine what subjects to exclude from parametric analyses

Subjects will be excluded if:
(1) they are missing p_want_of_resp for any block
(2) they do not have enough variability in p_want_of_resp to be included in analyses (must have >1 unique value)

```{r identify subs to exclude}

#### Identify subs with missing behavior for any block ####

# make list subjects with missing behavior for any block
pm_missing_pwant <- unique(beh[is.na(beh$p_want_of_resp),"id"])
pm_missing_pwant # 11, 39, 28, 20

# count number of subjects with missing data
nrow(pm_missing_pwant) # N = 4

#### clean data base ####

# remove subjects with missing data
pm_beh_temp <- beh[ ! beh$id %in% pm_missing_pwant$id, ]

# remove runs excluded for motion
censor_sum_subset <- censor_sum[,c("id", "run", "p_censor_interest")]
pm_beh_clean <- merge(x=pm_beh_temp,y=censor_sum_subset, 
             by=c("id","run"))
pm_beh_clean <-pm_beh_clean[!(pm_beh_clean$p_censor_interest>20),]
 
#### Identify subs with  no variability ####

# count number of distinct p_want values by id and ED condition (high, low)
distinct_ED <- pm_beh_clean %>% filter(cue_type != "office") %>%
  group_by(id, energy_density) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))

# count number of distinct p_want values by id and food PS condition (large, small)
distinct_PS_food <- pm_beh_clean %>% filter(cue_type != "office") %>%
  group_by(id, portion_size) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))

# count number of distinct p_want values by id for office condition (across large and small)
distinct_office<- pm_beh_clean %>% filter(cue_type != "food") %>%
  group_by(id) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))

# summarize # of distinct responses by energy_density and portion_size, and for office supplies
describeBy(distinct_ED$distinct, group = distinct_ED$energy_density)
describeBy(distinct_PS_food$distinct, group = distinct_PS_food$portion_size)
describe(distinct_office$distinct)

# Identify subs with  no variability (distinct==1) in at least 1 condition when assessing by ED
novar_ED <- distinct_ED[(distinct_ED$distinct==1),] %>%
  dplyr::summarize(distinct = n_distinct(id))
novar_ED$id # id 4, 40, 58
nrow(novar_ED) # N = 3

# Identify subs with no variability (distinct==1) in at least 1 condition when assessing by PS
novar_PS_food <- distinct_PS_food[(distinct_PS_food$distinct==1),] %>%
  dplyr::summarize(distinct = n_distinct(id))
novar_PS_food$id # id 4, 40
nrow(novar_PS_food) # N = 2

# Identify subs with no variability (distinct==1) in at least 1 condition when assessing by PS
novar_office <- distinct_office[(distinct_office$distinct==1),]
novar_office$id # id 4  17  26  49  56  84  89 116
nrow(novar_office) # N = 8

```
