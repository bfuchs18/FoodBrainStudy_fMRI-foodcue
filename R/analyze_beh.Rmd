---
title: "Behavioral Analyses"
author: "baf44"
date: "1/23/2023"
output: html_document
editor_options: 
  chunk_output_type: console
---

Code to plot and analyze in-scanner behavioral data (% wanting).

This code uses the following derivative files that were generated on Penn State's computing cluster and manually copied into data/derivatives_roar. These include:

(1) task-foodcue_summary.tsv
    This contains long summary data (by block) for behavior during the foodcue task
    This was generated by BIDS/code/foodcue_proc/p0_getbehavioral.py
(2) task-foodcue_byrun-censorsummary_fd-0.9.tsv
    This contains censor information (due to motion) for the foodcue task by run for each subject 
    This was generated by BIDS/code/afni/foodcue_proc/p2_create_censor_files.py
(3) index_all_fd-0.9_b20_3runs.txt
    This contains a list of subjects included in fmri analyses 
    This was generated by BIDS/code/afni/groupanalyses_paper1/prep_index_byrun.py

# Setup

```{r imports, include=FALSE}
library(lme4)
library(lmerTest) # need this to get p-values with anova()
library(plyr)
library(maditr)
library(ggplot2)
library(rstatix)
library(dplyr)
library(psych)
library(emmeans)
library(stringr)
library(ggsignif)

#### import BIDS derivatives to use in analyses ####

# import behavioral data
beh_all <- read.delim("BIDS/derivatives/preprocessed/beh/task-foodcue_summary.tsv") 

# import index file that specifies children included in analyses
index_wide <- read.table("BIDS//derivatives/analyses/foodcue-paper1/level2/index_all_fd-0.9_b20_3runs.txt", quote="\"", comment.char="")
index <- as.data.frame(t(index_wide)) # transpose index_wide to long dataframes
names(index) <- "id" # add column name

#censor sum database
censor_sum <- read.delim("BIDS/derivatives/preprocessed/fmriprep/task-foodcue_byrun-censorsummary_fd-0.9.tsv")
names(censor_sum)[names(censor_sum) == 'sub'] <- 'id'

```

Prepare dataframe of in-scanner behavior (p_want)

```{r prep beh dataset}
# remove condition letter (A-F) from block_proc 
beh_all$block_proc <- substring(beh_all$block_proc, 2)

# Add portion_size and cue-type columns
beh_all$portion_size <- ifelse(grepl("Large", beh_all$cond), "Larger", "Smaller")
beh_all$energy_density <- ifelse(grepl("High", beh_all$cond), "HighED", 
                       ifelse(grepl("Low", beh_all$cond), "LowED", "NA"))
beh_all$cue_type <- ifelse(grepl("High", beh_all$cond), "food", 
                       ifelse(grepl("Low", beh_all$cond), "food", "office"))
beh_all$category <- ifelse(grepl("High", beh_all$cond), "HighED", 
                       ifelse(grepl("Low", beh_all$cond), "LowED", "Office"))


# subset to children included for non-parametric fmri analyses
beh <- setDT(beh_all)[id %chin% index$id]

# create food-only dataframe by removing office conditions
beh_food<-beh[!(beh$cue_type=="office"),]

```

# Behavioral analyses

The following code analyses p_want by cue type/ED and amount and generates corresponding plots.
Behavior is assessed for all subjects included in non-parametric analyses (n=61).

Behavioral analyses:
``` {r p_want analyses}

# remove NAs -- not needed to run analyses, but helpful for predicting values to plot results
beh_clean <- beh[!is.na(beh$p_want_of_resp),]
beh_food_clean<-beh_food[!is.na(beh_food$p_want_of_resp),]

beh_clean$run <- as.factor(beh_clean$run)
beh_food_clean$run <- as.factor(beh_food_clean$run)


#### ANALYSES ####

# portion size (large, small) x cue type (food, office)
p_want_mixed_cuetype = lmer(p_want_of_resp ~ portion_size*cue_type + run + (1 | id), data = beh_clean)
anova(p_want_mixed_cuetype) # main effect of cue type

# portion size (large, small) x food-cue type (high, low)
p_want_mixed_ED = lmer(p_want_of_resp ~ portion_size*energy_density + run + (1 | id), data = beh_food_clean)
anova(p_want_mixed_ED)

# get means and ses 
emmeans(p_want_mixed_cuetype, specs = pairwise ~cue_type|portion_size, type = "response")
emmeans(p_want_mixed_ED, specs = pairwise ~energy_density|portion_size, type = "response")

```

Figure 1:
``` {r p_want plots}

# get adjusted response after adjusting for covariates in model 
beh_clean$predict_p_want_mixed_cuetype <- predict(p_want_mixed_cuetype, type="response")
beh_food_clean$predict_p_want_mixed_ED <- predict(p_want_mixed_ED, type="response")

#### VIOLIN PLOTS with ggplot####

# Amount (large, small) x cue (food, office)
plot_cuetype <- ggplot(beh_clean, aes(x=cue_type, y=predict_p_want_mixed_cuetype, fill = portion_size)) +
  theme_bw() +
  geom_violin(trim=FALSE)+
  geom_signif(comparisons = list(c("food","office")), y_position = 1.3,
              map_signif_level = TRUE)+
  geom_boxplot(aes(group = interaction(cue_type, portion_size)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(x="Cue Type",
       y = "Adjusted %want") +
  theme(legend.title = element_blank()) +
  theme(axis.text=element_text(size=12, color = "black"), axis.title=element_text(size=14,face="bold")) + 
  ylim(0, 1.5) + 
  scale_x_discrete(labels = c("food" = "Food",
                              "office" = "Office Supplies"))

plot_cuetype

# # Food amount (large, small) x ED (high, low)
plot_ED <- ggplot(beh_food_clean, aes(x=energy_density, y=predict_p_want_mixed_ED, fill = portion_size)) +
  theme_bw() +
  geom_violin(trim=FALSE)+
  geom_signif(comparisons = list(c("HighED","LowED")), y_position = 1.3,
              map_signif_level = TRUE) +
  geom_boxplot(aes(group = interaction(energy_density, portion_size)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(x="Energy Density",
       y = "Adjusted %want") +
  theme(legend.title = element_blank()) +
  theme(axis.text=element_text(size=12, color = "black"), axis.title=element_text(size=14,face="bold")) + 
  ylim(0, 1.5) +
  scale_x_discrete(labels = c("HighED" = "Higher",
                              "LowED" = "Lower"))

plot_ED


```

# Prepare for parametric analyses

The follow chunk is used to determine what subjects to exclude from parametric analyses

Subjects will be excluded if:
(1) they are missing p_want_of_resp for any block
(2) they do not have enough variability in p_want_of_resp to be included in analyses (must have >1 unique value)

```{r identify subs to exclude}

#### Identify subs with missing behavior for any block ####

# make list subjects with missing behavior for any block
pm_missing_pwant <- unique(beh[is.na(beh$p_want_of_resp),"id"])
pm_missing_pwant # 11, 39, 28, 20

# count number of subjects with missing data
nrow(pm_missing_pwant) # N = 4

#### clean data base ####

# remove subjects with missing data
pm_beh_temp <- beh[ ! beh$id %in% pm_missing_pwant$id, ]

# remove runs excluded for motion
censor_sum_subset <- censor_sum[,c("id", "run", "p_censor_interest")]
pm_beh_clean <- merge(x=pm_beh_temp,y=censor_sum_subset, 
             by=c("id","run"))
pm_beh_clean <-pm_beh_clean[!(pm_beh_clean$p_censor_interest>20),]
 
#### Identify subs with  no variability ####

# count number of distinct p_want values by id and ED condition (high, low)
distinct_ED <- pm_beh_clean %>% filter(cue_type != "office") %>%
  group_by(id, energy_density) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))

# count number of distinct p_want values by id and food PS condition (large, small)
distinct_PS_food <- pm_beh_clean %>% filter(cue_type != "office") %>%
  group_by(id, portion_size) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))

# count number of distinct p_want values by id for office condition (across large and small)
distinct_office<- pm_beh_clean %>% filter(cue_type != "food") %>%
  group_by(id) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))

# summarize # of distinct responses by energy_density and portion_size, and for office supplies
describeBy(distinct_ED$distinct, group = distinct_ED$energy_density)
describeBy(distinct_PS_food$distinct, group = distinct_PS_food$portion_size)
describe(distinct_office$distinct)

# Identify subs with  no variability (distinct==1) in at least 1 condition when assessing by ED
novar_ED <- distinct_ED[(distinct_ED$distinct==1),] %>%
  dplyr::summarize(distinct = n_distinct(id))
novar_ED$id # id 4, 40, 58
nrow(novar_ED) # N = 3

# Identify subs with no variability (distinct==1) in at least 1 condition when assessing by PS
novar_PS_food <- distinct_PS_food[(distinct_PS_food$distinct==1),] %>%
  dplyr::summarize(distinct = n_distinct(id))
novar_PS_food$id # id 4, 40
nrow(novar_PS_food) # N = 2

# Identify subs with no variability (distinct==1) in at least 1 condition when assessing by PS
novar_office <- distinct_office[(distinct_office$distinct==1),]
novar_office$id # id 4  17  26  49  56  84  89 116
nrow(novar_office) # N = 8

```

```{r average wanting by analyzed condition}
#### generate beh databases with analyzed sample ####

# remove subjects with no variability in p_want for the given analyses

# remove 4 and 40 -- not included in analyses by PS
pm_beh_food_analyzed_PS<-pm_beh_clean[!(pm_beh_clean$id==4 | pm_beh_clean$id==40),]

# remove 4 40 amd 58 -- not included in analyses by ED
pm_beh_food_analyzed_ED<-pm_beh_clean[!(pm_beh_clean$id==4 | pm_beh_clean$id==40 | pm_beh_clean$id==58),]

# remove  4  17  26  49  56  84  89 116 -- not included in analyses for office
pm_beh_analyzed_office<-pm_beh_clean[!(pm_beh_clean$id==4 | pm_beh_clean$id==17 | pm_beh_clean$id==26 | pm_beh_clean$id==49 | pm_beh_clean$id==56 | pm_beh_clean$id==84 | pm_beh_clean$id==89 | pm_beh_clean$id==116),]

#### count subs included in parametric analyses analyses ####
n_distinct(pm_beh_food_analyzed_PS$id)
n_distinct(pm_beh_food_analyzed_ED$id)
n_distinct(pm_beh_analyzed_office$id)

#### assess range in p_want responses by id, condition ####

# get min and max of distinct p_want values by id, ED condition
range_ED <- pm_beh_food_analyzed_ED %>%
  filter(cue_type == "food") %>% # remove office rows 
  group_by(id, energy_density) %>% 
  dplyr::summarize(min_pwant = min(p_want_of_resp), 
            max_pwant = max(p_want_of_resp),
            range_pwant = max(p_want_of_resp)- min(p_want_of_resp))

# get min and max of distinct p_want values by id, PS condition
range_PS <- pm_beh_food_analyzed_PS %>%
  filter(cue_type == "food") %>% 
  group_by(id, portion_size) %>% 
  dplyr::summarize(min_pwant = min(p_want_of_resp), 
            max_pwant = max(p_want_of_resp),
            range_pwant = max(p_want_of_resp)- min(p_want_of_resp))

# get min and max of distinct p_want values by id, office supplys
range_office <- pm_beh_analyzed_office %>%
  filter(cue_type == "office") %>% 
  group_by(id) %>% 
  dplyr::summarize(min_pwant = min(p_want_of_resp), 
            max_pwant = max(p_want_of_resp),
            range_pwant = max(p_want_of_resp)- min(p_want_of_resp))
  
# summarize range
describeBy(range_ED$range_pwant, group = range_ED$energy_density)
describeBy(range_PS$range_pwant, group = range_PS$portion_size)
describe(range_office$range_pwant)


hist(range_ED$range_pwant)
hist(range_PS$range_pwant)
hist(range_office$range_pwant)

```


```{r average wanting by analyzed condition}

# analyzed condtions: HighED, SmallED, LargePS, SmallPS

## datasets to use:
#pm_beh_food_analyzed_PS -- contains data for subjects included in parametric analyses by PS
#pm_beh_food_analyzed_ED -- contains data for subjects included in parametric analyses by ED
#pm_beh_analyzed_office -- contains data for subjects included in parametric analyses with office supplies

## NOTE: average here is calculated differently than for liking and fullness ratings -- for liking and fullness, ratings were averaged across all trials. here, % wanting is averaged across all blocks 

# subset beh into dataframes for each condition
beh_pwant_HighED <- pm_beh_food_analyzed_ED[pm_beh_food_analyzed_ED$energy_density == 'HighED',]
beh_pwant_LowED <- pm_beh_food_analyzed_ED[pm_beh_food_analyzed_ED$energy_density == 'LowED',]
beh_pwant_LargePS <- pm_beh_food_analyzed_PS[pm_beh_food_analyzed_PS$portion_size == 'Large',]
beh_pwant_SmallPS <- pm_beh_food_analyzed_PS[pm_beh_food_analyzed_PS$portion_size == 'Small',]

#create new data sets with person(i)-mean (pm) values for each condition
high_imeans <- ddply(beh_pwant_HighED, "id", summarize,
                       p_want_high_pm = mean(p_want_of_resp, na.rm=TRUE))

low_imeans <- ddply(beh_pwant_LowED, "id", summarize,
                       p_want_low_pm = mean(p_want_of_resp, na.rm=TRUE))

large_imeans <- ddply(beh_pwant_LargePS, "id", summarize,
                       p_want_large_pm = mean(p_want_of_resp, na.rm=TRUE))

small_imeans <- ddply(beh_pwant_SmallPS, "id", summarize,
                       p_want_small_pm = mean(p_want_of_resp, na.rm=TRUE))

# create wide trait data set -- will have the average wanting for each person, by condition (1 per column)
beh_pwant_trait <- NA
beh_pwant_trait <- merge(high_imeans, low_imeans, by="id", all=T)
beh_pwant_trait <- merge(beh_pwant_trait, large_imeans, by="id", all=T)
beh_pwant_trait <- merge(beh_pwant_trait, small_imeans, by="id", all=T)

# make long
beh_pwant_trait_long <- melt(beh_pwant_trait, id.vars=c("id"))

```


# Descriptive stats and plots

```{r avg p_want: descriptives and plot, include=TRUE}

# get descriptive stats for average (trait) wanting scores
## average wanting scores reflect each subjects percent wanting for each condition, averaged across all runs
## sd reflects between-person variability in trait wanting (i.e., the dispersion of each individual’s mean around the overall sample average (grand mean))

describe(beh_pwant_trait)

# Function to produce summary statistics (mean and +/- sd)
data_summary <- function(x) {
   m <- mean(x)
   m_minusSD <- m-sd(x)
   m_plusSD <- m+sd(x)
   return(c(y=m,ymin=m_minusSD,ymax=m_plusSD))
}

# violin plot with mean (dot) and +/- 1SD bar
ggplot(beh_pwant_trait_long, aes(x=variable, y=value)) + 
    geom_violin(trim=FALSE) + stat_summary(fun.data=data_summary)

# violin plot with dot plot
ggplot(beh_pwant_trait_long, aes(x=variable, y=value)) + 
    geom_violin(trim=FALSE) + 
    geom_dotplot(binaxis='y', stackdir='center', dotsize=1)

```
