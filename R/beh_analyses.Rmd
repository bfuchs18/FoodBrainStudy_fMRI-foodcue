---
title: "Behavioral Analyses"
author: "baf44"
date: "1/23/2023"
output: html_document
editor_options: 
  chunk_output_type: console
---

Code to plot and analyze in-scanner behavioral data (% wanting)

```{r setup, include=FALSE}
library(lme4)
library(lmerTest) # need this to get p-values with anova()
library(plyr)
library(maditr)
library(ggplot2)
library(rstatix)
library(dplyr)
library(psych)
library(emmeans)
library(stringr)

# import behavioral data
beh_all <- read.delim("data/databases/task-foodcue_summary.tsv")

# generate image_ratings databases
#source("R/data_org.R")

# source Alaina's functions
source("R/barplot_functions.R")

# import index file that specifies children included in analyses
index_wide <- read.table("data/databases/index_all_fd-0.9_b20_3runs.txt", quote="\"", comment.char="")
index <- as.data.frame(t(index_wide)) # transpose index_wide to long dataframes
names(index) <- "id" # add column name

#censor sum database
censor_sum <- read.delim("data/databases/task-foodcue_byrun-censorsummary_fd-0.9.tsv")
names(censor_sum)[names(censor_sum) == 'sub'] <- 'id'

#betas
rfusiform <- read.delim("data/databases/PM-ED_rfusiform_betas.txt")
names(rfusiform)[names(rfusiform) == 'sub'] <- 'id'

```

# Prepare dataframe of in-scanner behavior (p_want)
```{r prep beh dataset}
# remove condition letter (A-F) from block_proc 
beh_all$block_proc <- substring(beh_all$block_proc, 2)

# Add portion_size and cue-type columns
beh_all$portion_size <- ifelse(grepl("Large", beh_all$cond), "Large", "Small")
beh_all$energy_density <- ifelse(grepl("High", beh_all$cond), "HighED", 
                       ifelse(grepl("Low", beh_all$cond), "LowED", "NA"))
beh_all$cue_type <- ifelse(grepl("High", beh_all$cond), "food", 
                       ifelse(grepl("Low", beh_all$cond), "food", "office"))
beh_all$category <- ifelse(grepl("High", beh_all$cond), "HighED", 
                       ifelse(grepl("Low", beh_all$cond), "LowED", "Office"))


# subset to children included for non-parametric fmri analyses
beh <- setDT(beh_all)[id %chin% index$id]

# remove office conditions
beh_food<-beh[!(beh$cue_type=="office"),]

```

# p_want analyses on subjects included in non-parametric analyses 

Behavioral analyses:
``` {r p_want analyses}

# remove NAs -- not needed to run analyses, but helpful for predicting values to plot results
beh_clean <- beh[!is.na(beh$p_want_of_resp),]
beh_food_clean<-beh_food[!is.na(beh_food$p_want_of_resp),]

beh_clean$run <- as.factor(beh_clean$run)
beh_food_clean$run <- as.factor(beh_food_clean$run)


#### ANALYSES ####

# portion size (large, small) x cue type (food, office)
p_want_mixed_cuetype = lmer(p_want_of_resp ~ portion_size*cue_type + run + (1 | id), data = beh_clean)
anova(p_want_mixed_cuetype) # main effect of cue type

# portion size (large, small) x food-cue type (high, low)
p_want_mixed_ED = lmer(p_want_of_resp ~ portion_size*energy_density + run + (1 | id), data = beh_food_clean)
anova(p_want_mixed_ED)

# get means and ses 
emmeans(p_want_mixed_cuetype, specs = pairwise ~cue_type|portion_size, type = "response")
emmeans(p_want_mixed_ED, specs = pairwise ~energy_density|portion_size, type = "response")

```

Figure 1:
``` {r p_want plots}

# get predicted response after adjusting for covariates in model 
beh_clean$predict_p_want_mixed_all <- predict(p_want_mixed_all, type="response")
beh_clean$predict_p_want_mixed_cuetype <- predict(p_want_mixed_cuetype, type="response")
beh_food_clean$predict_p_want_mixed_ED <- predict(p_want_mixed_ED, type="response")

#### BAR PLOTS with ggplot####
# by category (high, low, office)
ggplot(data=beh_clean, aes(x=category, y=predict_p_want_mixed_all, fill=portion_size)) +
  geom_bar(stat="identity", position=position_dodge())+
  scale_fill_brewer(palette="Paired")+
  theme_minimal()

# by cue (food, office)
ggplot(data=beh_clean, aes(x=cue_type, y=predict_p_want_mixed_cuetype, fill=portion_size)) +
  geom_bar(stat="identity", position=position_dodge())+
  scale_fill_brewer(palette="Paired")+
  theme_minimal()

# by ED (high, low)
ggplot(data=beh_food_clean, aes(x=energy_density, y=predict_p_want_mixed_ED, fill=portion_size)) +
  geom_bar(stat="identity", position=position_dodge())+
  scale_fill_brewer(palette="Paired")+
  theme_minimal()

#### VIOLIN PLOTS with ggplot####

# by category (high, low, office)
plot_category <- ggplot(beh_clean, aes(x=category, y=predict_p_want_mixed_all, fill = portion_size)) +
  geom_violin(trim=FALSE)+
 # geom_signif(stat = "identity", inherit.aes = FALSE,
   #            data = data.frame(x = c(1.7, 0.7, 2.7), xend = c(3.3, 3.3, 3.3), y = c(105, 110, 85),  annotation = c("***", " ***", "*")),
  #             aes(x = x, xend = xend, y = y, yend = y, annotation = annotation)) +
  geom_boxplot(aes(group = interaction(category, portion_size)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(title="Percent want",
       x="category",
       y = "p_want") +
 # theme_pubr(base_size = 16) +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title = element_blank())

# by cue (food, office)
plot_cuetype <- ggplot(beh_clean, aes(x=cue_type, y=predict_p_want_mixed_cuetype, fill = portion_size)) +
  geom_violin(trim=FALSE)+
 # geom_signif(stat = "identity", inherit.aes = FALSE,
   #            data = data.frame(x = c(1.7, 0.7, 2.7), xend = c(3.3, 3.3, 3.3), y = c(105, 110, 85),  annotation = c("***", " ***", "*")),
  #             aes(x = x, xend = xend, y = y, yend = y, annotation = annotation)) +
  geom_boxplot(aes(group = interaction(cue_type, portion_size)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(title="Percent want",
       x="cue type",
       y = "p_want") +
 # theme_pubr(base_size = 16) +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title = element_blank()) +
    ylim(0, 1.5)


# by ED (high, low)
plot_ED <- ggplot(beh_food_clean, aes(x=energy_density, y=predict_p_want_mixed_ED, fill = portion_size)) +
  geom_violin(trim=FALSE)+
 # geom_signif(stat = "identity", inherit.aes = FALSE,
   #            data = data.frame(x = c(1.7, 0.7, 2.7), xend = c(3.3, 3.3, 3.3), y = c(105, 110, 85),  annotation = c("***", " ***", "*")),
  #             aes(x = x, xend = xend, y = y, yend = y, annotation = annotation)) +
  geom_boxplot(aes(group = interaction(energy_density, portion_size)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(title="Percent want",
       x="ED",
       y = "p_want") +
 # theme_pubr(base_size = 16) +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title = element_blank()) +
  ylim(0, 1.5)




#### BARPLOTS with alaina's function ####
ps_by_type <- data.frame(beh_clean$portion_size, beh_clean$cue_type)
mean_cond = means.function.na(beh_clean, beh_clean$p_want_of_resp, ps_by_type) # get mean ps and ed
se_cond = se.function.na(beh_clean, beh_clean$p_want_of_resp, ps_by_type)

beh_clean$portion_size <- as.factor(beh_clean$portion_size)
bar_graph.se(means = mean_cond, er = se_cond, xlab = "", ylab = "", ymax = 1, ymin = 0, group = beh_clean$portion_size)


#=
```


# Determine what subjects to exclude from parametric analyses

Subjects will be excluded if:
(1) they are missing p_want_of_resp for any block
(2) they do not have enough variability in p_want_of_resp to be included in analyses (must have >1 unique value)

Food cue only: -- this can be deleted 
```{r compute number of unique datapoints}
#### clean data base ####

# make list subjects with missing behavior for any block
missing_pwant <- unique(beh_food[is.na(beh_food$p_want_of_resp),"id"])
missing_pwant # 11, 39, 28, 20

# count number of subjects with missing data
nrow(missing_pwant) # N = 4

# remove subjects with missing data
beh_food_temp <- beh_food[ ! beh_food$id %in% missing_pwant$id, ]

# remove runs excluded for motion
censor_sum_subset <- censor_sum[,c("id", "run", "p_censor_interest")]
beh_food_clean <- merge(x=beh_food_temp,y=censor_sum_subset, 
             by=c("id","run"))
beh_food_clean <-beh_food_clean[!(beh_food_clean$p_censor_interest>20),]

# #### assess N unique responses in p_want responses by id, condition ####
# 
# # count number of distinct p_want values by id, ED condition
# distinct_ED <- beh_food_clean %>%
#   group_by(id, cue_type) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))
# 
# # count number of distinct p_want values by id, PS condition
# distinct_PS <- beh_food_clean %>%
#   group_by(id, portion_size) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))
#   
# # summarize # of distinct responses by cue_type and portion_size
# describeBy(distinct_ED$distinct, group = distinct_ED$cue_type)
# describeBy(distinct_PS$distinct, group = distinct_PS$portion_size)
# 
# # Identify subs with  no variability (distinct==1) in at least 1 condition when assessing by ED
# novar_ED <- distinct_ED[(distinct_ED$distinct==1),] %>%
#   dplyr::summarize(distinct = n_distinct(id))
# novar_ED$id # id 4, 40, 58
# nrow(novar_ED) # N = 3
# 
# # Identify subs with no variability (distinct==1) in at least 1 condition when assessing by PS
# novar_PS <- distinct_PS[(distinct_PS$distinct==1),] %>%
#   dplyr::summarize(distinct = n_distinct(id))
# novar_PS$id # id 4, 40
# nrow(novar_PS) # N = 2
# 
# 
# #### generate beh database with analyzed sample ####
# # remove subjects with no variability in p_want in at least 1 condition by ED or PS
# 
# # remove 4 and 40 -- not included in analyses by PS
# beh_food_analyzed_PS<-beh_food_clean[!(beh_food_clean$id==4 | beh_food_clean$id==40),]
# 
# # remove 4 40 amd 58 -- not included in analyses by ED
# beh_food_analyzed_ED<-beh_food_clean[!(beh_food_clean$id==4 | beh_food_clean$id==40 | beh_food_clean$id==58),]
# 
# 
# #### assess range in p_want responses by id, condition ####
# 
# # get min and max of distinct p_want values by id, ED condition
# range_ED <- beh_food_analyzed_ED %>%
#   group_by(id, cue_type) %>% 
#   dplyr::summarize(min_pwant = min(p_want_of_resp), 
#             max_pwant = max(p_want_of_resp),
#             range_pwant = max(p_want_of_resp)- min(p_want_of_resp))
# 
# # get min and max of distinct p_want values by id, PS condition
# range_PS <- beh_food_analyzed_PS %>%
#   group_by(id, portion_size) %>% 
#   dplyr::summarize(min_pwant = min(p_want_of_resp), 
#             max_pwant = max(p_want_of_resp),
#             range_pwant = max(p_want_of_resp)- min(p_want_of_resp))
#   
# # summarize range
# describeBy(range_ED$range_pwant, group = range_ED$cue_type)
# describeBy(range_PS$range_pwant, group = range_PS$portion_size)
# 
# hist(range_ED$range_pwant)
# hist(range_PS$range_pwant)
```

Food and office:
```{r identify subs to exclude}

#### Identify subs with missing behavior for any block ####

# make list subjects with missing behavior for any block
pm_missing_pwant <- unique(beh[is.na(beh$p_want_of_resp),"id"])
pm_missing_pwant # 11, 39, 28, 20

# count number of subjects with missing data
nrow(pm_missing_pwant) # N = 4

#### clean data base ####

# remove subjects with missing data
pm_beh_temp <- beh[ ! beh$id %in% pm_missing_pwant$id, ]

# remove runs excluded for motion
censor_sum_subset <- censor_sum[,c("id", "run", "p_censor_interest")]
pm_beh_clean <- merge(x=pm_beh_temp,y=censor_sum_subset, 
             by=c("id","run"))
pm_beh_clean <-pm_beh_clean[!(pm_beh_clean$p_censor_interest>20),]
 
#### Identify subs with  no variability ####

# count number of distinct p_want values by id and ED condition (high, low)
distinct_ED <- pm_beh_clean %>% filter(cue_type != "office") %>%
  group_by(id, energy_density) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))

# count number of distinct p_want values by id and food PS condition (large, small)
distinct_PS_food <- pm_beh_clean %>% filter(cue_type != "office") %>%
  group_by(id, portion_size) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))

# count number of distinct p_want values by id for office condition (across large and small)
distinct_office<- pm_beh_clean %>% filter(cue_type != "food") %>%
  group_by(id) %>% dplyr::summarize(distinct = n_distinct(p_want_of_resp))

# summarize # of distinct responses by energy_density and portion_size, and for office supplies
describeBy(distinct_ED$distinct, group = distinct_ED$energy_density)
describeBy(distinct_PS_food$distinct, group = distinct_PS_food$portion_size)
describe(distinct_office$distinct)

# Identify subs with  no variability (distinct==1) in at least 1 condition when assessing by ED
novar_ED <- distinct_ED[(distinct_ED$distinct==1),] %>%
  dplyr::summarize(distinct = n_distinct(id))
novar_ED$id # id 4, 40, 58
nrow(novar_ED) # N = 3

# Identify subs with no variability (distinct==1) in at least 1 condition when assessing by PS
novar_PS_food <- distinct_PS_food[(distinct_PS_food$distinct==1),] %>%
  dplyr::summarize(distinct = n_distinct(id))
novar_PS_food$id # id 4, 40
nrow(novar_PS_food) # N = 2

# Identify subs with no variability (distinct==1) in at least 1 condition when assessing by PS
novar_office <- distinct_office[(distinct_office$distinct==1),]
novar_office$id # id 4  17  26  49  56  84  89 116
nrow(novar_office) # N = 8


#### generate beh databases with analyzed sample ####

# remove subjects with no variability in p_want for the given analyses

# remove 4 and 40 -- not included in analyses by PS
pm_beh_food_analyzed_PS<-pm_beh_clean[!(pm_beh_clean$id==4 | pm_beh_clean$id==40),]

# remove 4 40 amd 58 -- not included in analyses by ED
pm_beh_food_analyzed_ED<-pm_beh_clean[!(pm_beh_clean$id==4 | pm_beh_clean$id==40 | pm_beh_clean$id==58),]

# remove  4  17  26  49  56  84  89 116 -- not included in analyses for office
pm_beh_analyzed_office<-pm_beh_clean[!(pm_beh_clean$id==4 | pm_beh_clean$id==17 | pm_beh_clean$id==26 | pm_beh_clean$id==49 | pm_beh_clean$id==56 | pm_beh_clean$id==84 | pm_beh_clean$id==89 | pm_beh_clean$id==116),]

#### count subs included in parametric analyses analyses ####
n_distinct(pm_beh_food_analyzed_PS$id)
n_distinct(pm_beh_food_analyzed_ED$id)
n_distinct(pm_beh_analyzed_office$id)

#### assess range in p_want responses by id, condition ####

# get min and max of distinct p_want values by id, ED condition
range_ED <- pm_beh_food_analyzed_ED %>%
  filter(cue_type == "food") %>% # remove office rows 
  group_by(id, energy_density) %>% 
  dplyr::summarize(min_pwant = min(p_want_of_resp), 
            max_pwant = max(p_want_of_resp),
            range_pwant = max(p_want_of_resp)- min(p_want_of_resp))

# get min and max of distinct p_want values by id, PS condition
range_PS <- pm_beh_food_analyzed_PS %>%
  filter(cue_type == "food") %>% 
  group_by(id, portion_size) %>% 
  dplyr::summarize(min_pwant = min(p_want_of_resp), 
            max_pwant = max(p_want_of_resp),
            range_pwant = max(p_want_of_resp)- min(p_want_of_resp))

# get min and max of distinct p_want values by id, office supplys
range_office <- pm_beh_analyzed_office %>%
  filter(cue_type == "office") %>% 
  group_by(id) %>% 
  dplyr::summarize(min_pwant = min(p_want_of_resp), 
            max_pwant = max(p_want_of_resp),
            range_pwant = max(p_want_of_resp)- min(p_want_of_resp))
  
# summarize range
describeBy(range_ED$range_pwant, group = range_ED$energy_density)
describeBy(range_PS$range_pwant, group = range_PS$portion_size)
describe(range_office$range_pwant)


hist(range_ED$range_pwant)
hist(range_PS$range_pwant)
hist(range_office$range_pwant)

```


```{r average wanting by analyzed condition}

# analyzed condtions: HighED, SmallED, LargePS, SmallPS

## datasets to use:
#pm_beh_food_analyzed_PS -- contains data for subjects included in parametric analyses by PS
#pm_beh_food_analyzed_ED -- contains data for subjects included in parametric analyses by ED
#pm_beh_analyzed_office -- contains data for subjects included in parametric analyses with office supplies

## NOTE: average here is calculated differently than for liking and fullness ratings -- for liking and fullness, ratings were averaged across all trials. here, % wanting is averaged across all blocks 

# subset beh into dataframes for each condition
beh_pwant_HighED <- pm_beh_food_analyzed_ED[pm_beh_food_analyzed_ED$energy_density == 'HighED',]
beh_pwant_LowED <- pm_beh_food_analyzed_ED[pm_beh_food_analyzed_ED$energy_density == 'LowED',]
beh_pwant_LargePS <- pm_beh_food_analyzed_PS[pm_beh_food_analyzed_PS$portion_size == 'Large',]
beh_pwant_SmallPS <- pm_beh_food_analyzed_PS[pm_beh_food_analyzed_PS$portion_size == 'Small',]

#create new data sets with person(i)-mean (pm) values for each condition
high_imeans <- ddply(beh_pwant_HighED, "id", summarize,
                       p_want_high_pm = mean(p_want_of_resp, na.rm=TRUE))

low_imeans <- ddply(beh_pwant_LowED, "id", summarize,
                       p_want_low_pm = mean(p_want_of_resp, na.rm=TRUE))

large_imeans <- ddply(beh_pwant_LargePS, "id", summarize,
                       p_want_large_pm = mean(p_want_of_resp, na.rm=TRUE))

small_imeans <- ddply(beh_pwant_SmallPS, "id", summarize,
                       p_want_small_pm = mean(p_want_of_resp, na.rm=TRUE))

# create wide trait data set -- will have the average wanting for each person, by condition (1 per column)
beh_pwant_trait <- NA
beh_pwant_trait <- merge(high_imeans, low_imeans, by="id", all=T)
beh_pwant_trait <- merge(beh_pwant_trait, large_imeans, by="id", all=T)
beh_pwant_trait <- merge(beh_pwant_trait, small_imeans, by="id", all=T)

# make long
beh_pwant_trait_long <- melt(beh_pwant_trait, id.vars=c("id"))

```


# Descriptive stats and plots

```{r in-scanner response rate, include=TRUE}
```

```{r avg p_want: descriptives and plot, include=TRUE}

# get descriptive stats for average (trait) wanting scores
## average wanting scores reflect each subjects percent wanting for each condition, averaged across all runs
## sd reflects between-person variability in trait wanting (i.e., the dispersion of each individual’s mean around the overall sample average (grand mean))

describe(beh_pwant_trait)

# Function to produce summary statistics (mean and +/- sd)
data_summary <- function(x) {
   m <- mean(x)
   m_minusSD <- m-sd(x)
   m_plusSD <- m+sd(x)
   return(c(y=m,ymin=m_minusSD,ymax=m_plusSD))
}

# violin plot with mean (dot) and +/- 1SD bar
ggplot(beh_pwant_trait_long, aes(x=variable, y=value)) + 
    geom_violin(trim=FALSE) + stat_summary(fun.data=data_summary)

# violin plot with dot plot
ggplot(beh_pwant_trait_long, aes(x=variable, y=value)) + 
    geom_violin(trim=FALSE) + 
    geom_dotplot(binaxis='y', stackdir='center', dotsize=1)

```

```{r within-person p_want descriptives, include=TRUE}

# Within-person variability: the dispersion of each individual’s score around person’s own average (person mean)


# for each condition, fit empty model predicting p_want_of_resp from random intercept
emptymodel_high <- lmer(formula = p_want_of_resp ~ 1 + (1|id), 
              data=beh_pwant_HighED,
              na.action=na.exclude)

emptymodel_low <- lmer(formula = p_want_of_resp ~ 1 + (1|id), 
              data=beh_pwant_LowED,
              na.action=na.exclude)

emptymodel_large <- lmer(formula = p_want_of_resp ~ 1 + (1|id), 
              data=beh_pwant_LargePS,
              na.action=na.exclude)

emptymodel_small <- lmer(formula = p_want_of_resp ~ 1 + (1|id), 
              data=beh_pwant_SmallPS,
              na.action=na.exclude)

summary(emptymodel_high)
summary(emptymodel_low)
summary(emptymodel_large)
summary(emptymodel_small)

# use intecepts and residuals from empty model to assess within-person variance -- but how??? MVM class 6
randeff_high <- as.data.frame(VarCorr(emptymodel_high)) # extract variance and sd components 
int_high <- randeff_high[1,4] # extract intercept
residual_high <- randeff_high[2,4] # extract residual
residual_sd_high <- randeff_high[2,5] # extract residual sd

randeff_low <- as.data.frame(VarCorr(emptymodel_low)) # extract variance and sd components 
int_low <- randeff_low[1,4] # extract intercept
residual_low <- randeff_low[2,4] # extract residual
residual_sd_low <- randeff_low[2,5] # extract residual sd

randeff_large <- as.data.frame(VarCorr(emptymodel_large)) # extract variance and sd components 
int_large <- randeff_large[1,4] # extract intercept
residual_large <- randeff_large[2,4] # extract residual
residual_sd_large <- randeff_large[2,5] # extract residual sd

randeff_small <- as.data.frame(VarCorr(emptymodel_small)) # extract variance and sd components 
int_small <- randeff_small[1,4] # extract intercept
residual_small <- randeff_small[2,4] # extract residual
residual_sd_small <- randeff_small[2,5] # extract residual sd


# ICC : the % of total variability that is between-person (percent of variabilty due to differences between people)
ICC_between_high <- int_high / (int_high + residual_high)
ICC_between_low <- int_low / (int_low + residual_low)
ICC_between_large <- int_large / (int_large + residual_large)
ICC_between_small <- int_small / (int_small + residual_small)

```

```{r plot behavior by run/block procedure}

beh_food_analyzed_PS$run <- as.factor(beh_food_analyzed_PS$run)
beh_food_analyzed_ED$run <- as.factor(beh_food_analyzed_ED$run)

#### wanting by run ####
# facet box plots -- plot wanting for each condition across runs
want_byrun <- ggplot(beh_food_clean, aes(x=run, y=p_want_of_resp, fill=cond)) + 
    geom_boxplot() +
    facet_wrap(~cond)
want_byrun

#### wanting by block procedure ####
# facet box plots -- plot wanting across block_proc (order of block_proc differered between versions A and B)
# By Portion size ## PROBLEM: EACH SUBJECT WILL HAVE 2 DATA POINTS PER BLOCK_PROC
want_byproc_PS <- ggplot(beh_food_analyzed_PS, aes(x=block_proc, y=p_want_of_resp, fill=portion_size)) + 
    geom_boxplot() +
    facet_wrap(~portion_size)
want_byproc_PS

# By ED ## PROBLEM: EACH SUBJECT WILL HAVE 2 DATA POINTS PER BLOCK_PROC
want_byproc_ED <- ggplot(beh_food_analyzed_ED, aes(x=block_proc, y=p_want_of_resp, fill=cue_type)) + 
    geom_boxplot() +
    facet_wrap(~cue_type)
want_byproc_ED

#### liking by block procedure ####
# subset liking
like_byproc <- avg_ratings[,grep("id|^like_a|^like_b|^like_c|^like_d", colnames(avg_ratings))]

# wide to long
like_byproc_long <- gather(data = like_byproc, key = block_proc, like_a1:like_d5,value = avg_like)

# remove "like_" from 
like_byproc_long$block_proc<-gsub("like_","",as.character(like_byproc_long$block_proc))

# split block_proc into 2 columns (split on first character of block_proc)
like_byproc_long <- like_byproc_long %>% separate(block_proc, c("cond", "proc"), sep = 1)

# facet box plots -- plot liking for each food condition across block_proc
like_byproc <- ggplot(like_byproc_long, aes(x=proc, y=avg_like, fill=cond)) + 
    geom_boxplot() +
    facet_wrap(~cond)
like_byproc

#### fullness by block procedure ####
full_byproc <- avg_ratings[,grep("id|^full_a|^full_b|^full_c|^full_d", colnames(avg_ratings))]

# wide to long
full_byproc_long <- gather(data = full_byproc, key = block_proc, full_a1:full_d5,value = avg_full)

# remove "full_" from 
full_byproc_long$block_proc<-gsub("full_","",as.character(full_byproc_long$block_proc))

# split block_proc into 2 columns (split on first character of block_proc)
full_byproc_long <- full_byproc_long %>% separate(block_proc, c("cond", "proc"), sep = 1)

# facet box plots -- plot liking for each food condition across block_proc
full_byproc <- ggplot(full_byproc_long, aes(x=proc, y=avg_full, fill=cond)) + 
    geom_boxplot() +
    facet_wrap(~cond)
full_byproc
```


# Analyses

``` {r post-scan rating analyses}

# subject food only
like_long_food <- like_long[like_long$type != 'Office', ]

####  repeated measures anovas ####
# PS (Large, Small) x Type (High, Low, Office) on liking
liking_all.aov <- anova_test(
  data = like_long, dv = avg_liking, wid = id,
  within = c(type, portion_size)
  )
get_anova_table(liking.aov)

# PS (Large, Small) x ED (High, Low) on liking
liking_food.aov <- anova_test(
  data = like_long, dv = avg_liking, wid = id,
  within = c(type, portion_size)
  )
get_anova_table(liking_food.aov)

# PS (Large, Small) x ED (High, Low) on percieved fullness
fullness.aov <- anova_test(
  data = full_long, dv = avg_fullness, wid = id,
  within = c(type, portion_size)
  )
get_anova_table(fullness.aov)

# correlation between difference scores

cor.test(analyzed_df$full_LvS_overall, analyzed_df$like_LvS_overall, use = "complete.obs")

cor.test(analyzed_df$full_HvL_overall, analyzed_df$like_HvL_overall, use = "complete.obs")
# the more full a child reports for high vs. low ED foods, the more they report liking high vs. low ED foods

```

``` {r BOLD correlation}
library(stringr)

# clean betas dataframe
rfusiform$high_beta_temp <- str_trim(rfusiform$high_beta) # removes white space at start of string
rfusiform$low_beta_temp <- str_trim(rfusiform$low_beta) # removes white space at start of string

rfusiform$high_beta <- as.numeric(sub(" .*", "", rfusiform$high_beta_temp)) # remove everything after first " ", make numeric
rfusiform$low_beta <- as.numeric(sub(" .*", "", rfusiform$low_beta_temp)) # remove everything after first " ", make numeric

# wide to long
rfusiform_long <- reshape2::melt(rfusiform,
        # ID variables - all the variables to keep but not split apart on
    id.vars=c("id"),
        # The source columns
    measure.vars=c("high_beta","low_beta"),
        # Name of the destination column that will identify the original
        # column that the measurement came from
    variable.name="condition",
    value.name="betas"
)

#### full sample stats ####
# summary stats
rfusiform_long %>%
  group_by(condition) %>%
  get_summary_stats(betas, type = "common")

# violin plot
ggplot(rfusiform_long, aes(x=condition, y=betas)) + 
    geom_violin(trim=FALSE) + 
    geom_dotplot(binaxis='y', stackdir='center', dotsize=1)

# t-test
t.test(rfusiform$high_beta, rfusiform$low_beta, paired = TRUE, alternative = "two.sided")

#### remove 120 ####
rfusiform_long_no120<-rfusiform_long[!(rfusiform_long$id==120) ,]
rfusiform_no120<-rfusiform[!(rfusiform$id==120) ,]

# violin plot
ggplot(rfusiform_long_no120, aes(x=condition, y=betas)) + 
    geom_violin(trim=FALSE) + 
    geom_dotplot(binaxis='y', stackdir='center', dotsize=1)

# t-test
t.test(rfusiform_no120$high_beta, rfusiform_no120$low_beta, paired = TRUE, alternative = "two.sided")
# still significantly different without 120

#### remove 55 ####
rfusiform_long_no55<-rfusiform_long[!(rfusiform_long$id==55) ,]
rfusiform_no55<-rfusiform[!(rfusiform$id==55) ,]

# violin plot
ggplot(rfusiform_long_no55, aes(x=condition, y=betas)) + 
    geom_violin(trim=FALSE) + 
    geom_dotplot(binaxis='y', stackdir='center', dotsize=1)

# t-test
t.test(rfusiform_no55$high_beta, rfusiform_no55$low_beta, paired = TRUE, alternative = "two.sided")
# still significantly different without 55

#### remove 120 and 55 ####
rfusiform_long_nooutliers<-rfusiform_long[!(rfusiform_long$id==55 | rfusiform_long$id==120) ,]
rfusiform_nooutliers<-rfusiform[!(rfusiform_long$id==55 | rfusiform_long$id==120) ,]

# violin plot
ggplot(rfusiform_long_nooutliers, aes(x=condition, y=betas)) + 
    geom_violin(trim=FALSE) + 
    geom_dotplot(binaxis='y', stackdir='center', dotsize=1)

# t-test
t.test(rfusiform_nooutliers$high_beta, rfusiform_nooutliers$low_beta, paired = TRUE, alternative = "two.sided")
# still significantly different without 55 and 120

# summary stats
rfusiform_long_nooutliers %>%
  group_by(condition) %>%
  get_summary_stats(betas, type = "common")

```
