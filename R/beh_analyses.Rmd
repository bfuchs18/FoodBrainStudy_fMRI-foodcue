---
title: "Behavioral Analyses"
author: "baf44"
date: "1/23/2023"
output: html_document
editor_options: 
  chunk_output_type: console
---

Code to plot and analyze behavioral data (liking, anticipated fullness, wanting)

```{r setup, include=FALSE}
library(lme4)
library(lmerTest) # need this to get p-values with anova()
library(plyr)
library(maditr)
library(ggplot2)
library(rstatix)
library(dplyr)

# import behavioral data
beh_all <- read.delim("data/databases/task-foodcue_summary.tsv")
image_ratings_all <- read.csv("data/compiled/fmri_image_ratings.csv")

# source Alaina's functions
source("R/barplot_functions.R")

# import index file that specifies children included in analyses
index_wide <- read.table("data/databases/index_all_fd-0.9_b20_3runs.txt", quote="\"", comment.char="")
index <- as.data.frame(t(index_wide)) # transpose index_wide to long dataframes
names(index) <- "id" # add column name

# subset to those in analyses
beh <- setDT(beh_all)[id %chin% index$id] # subset dataframes to only include children in fmri analyses
image_ratings <- setDT(image_ratings_all)[id %chin% index$id] # subset dataframes to only include children in fmri analyses

#censor sum database
censor_sum <- read.delim("data/databases/task-foodcue_byrun-censorsummary_fd-0.9.tsv")
names(censor_sum)[names(censor_sum) == 'sub'] <- 'id'
```

# Prepare post-scanner ratings
```{r compute avg liking and fullness ratings}
# Conditions:
# A = HighLarge
# B = HighSmall
# C = LowLarge
# D = LowSmall
# E = OfficeLarge
# F = OfficeSmall

#### compute average liking ratings  ####
# note: in grep, ^ indicates the start of the string, $ indicates the end, .+ gets everything in between

# for each condition overall
image_ratings$like_HighLarge <- rowMeans(image_ratings[grep('^mrivas_a.+like$', names(image_ratings))])
image_ratings$like_HighSmall <- rowMeans(image_ratings[grep('^mrivas_b.+like$', names(image_ratings))])
image_ratings$like_LowLarge <- rowMeans(image_ratings[grep('^mrivas_c.+like$', names(image_ratings))])
image_ratings$like_LowSmall <- rowMeans(image_ratings[grep('^mrivas_d.+like$', names(image_ratings))])
image_ratings$like_OfficeLarge <- rowMeans(image_ratings[grep('^mrivas_e.+like$', names(image_ratings))])
image_ratings$like_OfficeSmall <- rowMeans(image_ratings[grep('^mrivas_f.+like$', names(image_ratings))])

# for each condition by block procedure 
image_ratings$like_a1 <- rowMeans(image_ratings[grep('^mrivas_a1.+like$', names(image_ratings))])
image_ratings$like_a2 <- rowMeans(image_ratings[grep('^mrivas_a2.+like$', names(image_ratings))])
image_ratings$like_a3 <- rowMeans(image_ratings[grep('^mrivas_a3.+like$', names(image_ratings))])
image_ratings$like_a4 <- rowMeans(image_ratings[grep('^mrivas_a4.+like$', names(image_ratings))])
image_ratings$like_a5 <- rowMeans(image_ratings[grep('^mrivas_a5.+like$', names(image_ratings))])

image_ratings$like_b1 <- rowMeans(image_ratings[grep('^mrivas_b1.+like$', names(image_ratings))])
image_ratings$like_b2 <- rowMeans(image_ratings[grep('^mrivas_b2.+like$', names(image_ratings))])
image_ratings$like_b3 <- rowMeans(image_ratings[grep('^mrivas_b3.+like$', names(image_ratings))])
image_ratings$like_b4 <- rowMeans(image_ratings[grep('^mrivas_b4.+like$', names(image_ratings))])
image_ratings$like_b5 <- rowMeans(image_ratings[grep('^mrivas_b5.+like$', names(image_ratings))])

image_ratings$like_c1 <- rowMeans(image_ratings[grep('^mrivas_c1.+like$', names(image_ratings))])
image_ratings$like_c2 <- rowMeans(image_ratings[grep('^mrivas_c2.+like$', names(image_ratings))])
image_ratings$like_c3 <- rowMeans(image_ratings[grep('^mrivas_c3.+like$', names(image_ratings))])
image_ratings$like_c4 <- rowMeans(image_ratings[grep('^mrivas_c4.+like$', names(image_ratings))])
image_ratings$like_c5 <- rowMeans(image_ratings[grep('^mrivas_c5.+like$', names(image_ratings))])

image_ratings$like_d1 <- rowMeans(image_ratings[grep('^mrivas_d1.+like$', names(image_ratings))])
image_ratings$like_d2 <- rowMeans(image_ratings[grep('^mrivas_d2.+like$', names(image_ratings))])
image_ratings$like_d3 <- rowMeans(image_ratings[grep('^mrivas_d3.+like$', names(image_ratings))])
image_ratings$like_d4 <- rowMeans(image_ratings[grep('^mrivas_d4.+like$', names(image_ratings))])
image_ratings$like_d5 <- rowMeans(image_ratings[grep('^mrivas_d5.+like$', names(image_ratings))])

image_ratings$like_e1 <- rowMeans(image_ratings[grep('^mrivas_e1.+like$', names(image_ratings))])
image_ratings$like_e2 <- rowMeans(image_ratings[grep('^mrivas_e2.+like$', names(image_ratings))])
image_ratings$like_e3 <- rowMeans(image_ratings[grep('^mrivas_e3.+like$', names(image_ratings))])
image_ratings$like_e4 <- rowMeans(image_ratings[grep('^mrivas_e4.+like$', names(image_ratings))])
image_ratings$like_e5 <- rowMeans(image_ratings[grep('^mrivas_e5.+like$', names(image_ratings))])

image_ratings$like_f1 <- rowMeans(image_ratings[grep('^mrivas_f1.+like$', names(image_ratings))])
image_ratings$like_f2 <- rowMeans(image_ratings[grep('^mrivas_f2.+like$', names(image_ratings))])
image_ratings$like_f3 <- rowMeans(image_ratings[grep('^mrivas_f3.+like$', names(image_ratings))])
image_ratings$like_f4 <- rowMeans(image_ratings[grep('^mrivas_f4.+like$', names(image_ratings))])
image_ratings$like_f5 <- rowMeans(image_ratings[grep('^mrivas_f5.+like$', names(image_ratings))])

# across conditions
image_ratings$like_HighED <- rowMeans(image_ratings[grep('^mrivas_a.+like$|mrivas_b.+like$', names(image_ratings))])
image_ratings$like_LowED <- rowMeans(image_ratings[grep('^mrivas_c.+like$|mrivas_d.+like$', names(image_ratings))])
image_ratings$like_LargePS <- rowMeans(image_ratings[grep('^mrivas_a.+like$|mrivas_c.+like$', names(image_ratings))])
image_ratings$like_SmallPS <- rowMeans(image_ratings[grep('^mrivas_b.+like$|mrivas_d.+like$', names(image_ratings))])
image_ratings$like_Office <- rowMeans(image_ratings[grep('^mrivas_e.+like$|mrivas_f.+like$', names(image_ratings))])
image_ratings$like_food <- rowMeans(image_ratings[grep('^mrivas_a.+like$|mrivas_b.+like$|^mrivas_c.+like$|mrivas_d.+like$', names(image_ratings))])

#### compute average fullness ratings  ####
# for each food condition overall
image_ratings$full_HighLarge <- rowMeans(image_ratings[grep('^mrivas_a.+full$', names(image_ratings))])
image_ratings$full_HighSmall <- rowMeans(image_ratings[grep('^mrivas_b.+full$', names(image_ratings))])
image_ratings$full_LowLarge <- rowMeans(image_ratings[grep('^mrivas_c.+full$', names(image_ratings))])
image_ratings$full_LowSmall <- rowMeans(image_ratings[grep('^mrivas_d.+full$', names(image_ratings))])

# for each food condition by block procedure
image_ratings$full_a1 <- rowMeans(image_ratings[grep('^mrivas_a1.+full$', names(image_ratings))])
image_ratings$full_a2 <- rowMeans(image_ratings[grep('^mrivas_a2.+full$', names(image_ratings))])
image_ratings$full_a3 <- rowMeans(image_ratings[grep('^mrivas_a3.+full$', names(image_ratings))])
image_ratings$full_a4 <- rowMeans(image_ratings[grep('^mrivas_a4.+full$', names(image_ratings))])
image_ratings$full_a5 <- rowMeans(image_ratings[grep('^mrivas_a5.+full$', names(image_ratings))])

image_ratings$full_b1 <- rowMeans(image_ratings[grep('^mrivas_b1.+full$', names(image_ratings))])
image_ratings$full_b2 <- rowMeans(image_ratings[grep('^mrivas_b2.+full$', names(image_ratings))])
image_ratings$full_b3 <- rowMeans(image_ratings[grep('^mrivas_b3.+full$', names(image_ratings))])
image_ratings$full_b4 <- rowMeans(image_ratings[grep('^mrivas_b4.+full$', names(image_ratings))])
image_ratings$full_b5 <- rowMeans(image_ratings[grep('^mrivas_b5.+full$', names(image_ratings))])

image_ratings$full_c1 <- rowMeans(image_ratings[grep('^mrivas_c1.+full$', names(image_ratings))])
image_ratings$full_c2 <- rowMeans(image_ratings[grep('^mrivas_c2.+full$', names(image_ratings))])
image_ratings$full_c3 <- rowMeans(image_ratings[grep('^mrivas_c3.+full$', names(image_ratings))])
image_ratings$full_c4 <- rowMeans(image_ratings[grep('^mrivas_c4.+full$', names(image_ratings))])
image_ratings$full_c5 <- rowMeans(image_ratings[grep('^mrivas_c5.+full$', names(image_ratings))])

image_ratings$full_d1 <- rowMeans(image_ratings[grep('^mrivas_d1.+full$', names(image_ratings))])
image_ratings$full_d2 <- rowMeans(image_ratings[grep('^mrivas_d2.+full$', names(image_ratings))])
image_ratings$full_d3 <- rowMeans(image_ratings[grep('^mrivas_d3.+full$', names(image_ratings))])
image_ratings$full_d4 <- rowMeans(image_ratings[grep('^mrivas_d4.+full$', names(image_ratings))])
image_ratings$full_d5 <- rowMeans(image_ratings[grep('^mrivas_d5.+full$', names(image_ratings))])

# across conditions
image_ratings$full_LargePS <- rowMeans(image_ratings[grep('^mrivas_a.+full$|mrivas_c.+full$', names(image_ratings))])
image_ratings$full_SmallPS <- rowMeans(image_ratings[grep('^mrivas_b.+full$|mrivas_d.+full$', names(image_ratings))])
image_ratings$full_HighED <- rowMeans(image_ratings[grep('^mrivas_a.+full$|mrivas_b.+full$', names(image_ratings))])
image_ratings$full_LowED <- rowMeans(image_ratings[grep('^mrivas_c.+full$|mrivas_d.+full$', names(image_ratings))])

#### compute difference scores ####
# compute large - small fullness difference scores
image_ratings$full_LvS_overall <- (image_ratings$full_LargePS - image_ratings$full_SmallPS)
image_ratings$full_LvS_hed <- (image_ratings$full_HighLarge - image_ratings$full_HighSmall)
image_ratings$full_LvS_led <- (image_ratings$full_LowLarge - image_ratings$full_LowSmall)

# compute large - small liking difference scores
image_ratings$like_LvS_overall <- (image_ratings$like_LargePS - image_ratings$like_SmallPS)
image_ratings$like_LvS_hed <- (image_ratings$like_HighLarge - image_ratings$like_HighSmall)
image_ratings$like_LvS_led <- (image_ratings$like_LowLarge - image_ratings$like_LowSmall)

# compute high - low fullness difference scores
image_ratings$full_HvL_overall <- (image_ratings$full_HighED - image_ratings$full_LowED)
image_ratings$full_HvL_large <- (image_ratings$full_HighLarge - image_ratings$full_LowLarge)
image_ratings$full_HvL_small <- (image_ratings$full_HighSmall - image_ratings$full_LowSmall)

# compute high - low liking difference scores
image_ratings$like_HvL_overall <- (image_ratings$like_HighED - image_ratings$like_LowED)
image_ratings$like_HvL_large <- (image_ratings$like_HighLarge - image_ratings$like_LowLarge)
image_ratings$like_HvL_small <- (image_ratings$like_HighSmall - image_ratings$like_LowSmall)


#subset liking and fullness data
avg_ratings <- image_ratings[,grep("id|^like|^full", colnames(image_ratings))]

```

```{r prep beh datasets}
# wide to long -- liking ratings 
like_long <- reshape2::melt(avg_ratings,
        # ID variables - all the variables to keep but not split apart on
    id.vars=c("id"),
        # The source columns
    measure.vars=c("like_HighLarge","like_HighSmall", "like_LowLarge", "like_LowSmall", "like_OfficeLarge", "like_OfficeSmall"),
        # Name of the destination column that will identify the original
        # column that the measurement came from
    variable.name="condition",
    value.name="avg_liking"
)

# wide to long -- fullness ratings
full_long <- reshape2::melt(avg_ratings,
        # ID variables - all the variables to keep but not split apart on
    id.vars=c("id"),
        # The source columns
    measure.vars=c("full_HighLarge","full_LowLarge", "full_HighSmall", "full_LowSmall"),
        # Name of the destination column that will identify the original
        # column that the measurement came from
    variable.name="condition",
    value.name="avg_fullness"
)

# Make portion size and energy density columns
like_long$portion_size <- ifelse(grepl("Large", like_long$cond), "Large", "Small")
like_long$type <- ifelse(grepl("High", like_long$condition), "HighED", ifelse(grepl("Low", like_long$condition), "LowED", "Office"))
full_long$portion_size <- ifelse(grepl("Large", full_long$condition), "Large", "Small")
full_long$type <- ifelse(grepl("High", full_long$condition), "High", "Low")

# wide to long -- fullness difference score
full_diff_ratings_long <- melt(avg_ratings,
        # ID variables - all the variables to keep but not split apart on
    id.vars=c("id"),
        # The source columns
    measure.vars=c("full_LvS_overall","full_LvS_hed", "full_LvS_led"),
        # Name of the destination column that will identify the original
        # column that the measurement came from
    variable.name="condition",
    value.name="LvS_fullness"
)
```

# Prepare in-scanner behavior
```{r prep beh dataset}
# remove condition letter (A-F) from block_proc 
beh$block_proc <- substring(beh$block_proc, 2)

# Add portion_size and cue-type columns
beh$portion_size <- ifelse(grepl("Large", beh$cond), "Large", "Small")
beh$cue_type <- ifelse(grepl("High", beh$cond), "HighED", 
                       ifelse(grepl("Low", beh$cond), "LowED", "Office"))

```

# Are parametric analyses on p_want and food cue response feasible?
```{r compute number of unique datapoints}
#### clean data base ####

# remove office conditions
beh_food<-beh[!(beh$cond=="OfficeLarge" | beh$cond=="OfficeSmall"),]

# make list subjects with missing behavior for any block
missing_pwant <- unique(beh_food[is.na(beh_food$p_want_of_resp),"id"])
missing_pwant # 11, 39, 28, 20

# count number of subjects with missing data
nrow(missing_pwant) # N = 4

# remove subjects with missing data
beh_food_temp <- beh_food[ ! beh_food$id %in% missing_pwant$id, ]

# remove runs excluded for motion
censor_sum_subset <- censor_sum[,c("id", "run", "p_censor_interest")]
beh_food_clean <- merge(x=beh_food_temp,y=censor_sum_subset, 
             by=c("id","run"))
beh_food_clean <-beh_food_clean[!(beh_food_clean$p_censor_interest>20),]

#### assess variability in p_want responses across blocks ####
# likely cant do parametric analyses if only 1 value for a condition across runs

# count number of distinct p_want values by id, ED condition
distict_ED <- beh_food_clean %>%
  group_by(id, cue_type) %>% summarize(distinct = n_distinct(p_want_of_resp))

# count number of distinct p_want values by id, PS condition
distict_PS <- beh_food_clean %>%
  group_by(id, portion_size) %>% summarize(distinct = n_distinct(p_want_of_resp))
  
# summarize # of distinct responses by cue_type and portion_size
describeBy(distinct_ED$distinct, group = distinct_ED$cue_type)
describeBy(distict_PS$distinct, group = distict_PS$portion_size)

# Identify subs with  no variability (distinct==1) in at least 1 condition when assessing by ED
novar_ED <- distict_ED[(distict_ED$distinct==1),] %>%
  summarize(distinct = n_distinct(id))
novar_ED$id # id 4, 40, 58
nrow(novar_ED) # N = 3

# Identify subs with no variability (distinct==1) in at least 1 condition when assessing by PS
novar_PS <- distict_PS[(distict_PS$distinct==1),] %>%
  summarize(distinct = n_distinct(id))
novar_PS$id # id 4, 40
nrow(novar_PS) # N = 2

## Can we add a little error to p_want for subjects with no variability so that we can keep them in model? -- could test with and without 
```


```{r average wanting by condition}

## NOTE: average here is calculated differently than for liking and fullness ratings -- for liking and fullness, ratings were averaged across all trials. here, % wanting is averaged across all blocks 

# subset beh into dataframes for each condition
beh_pwant_hl <- beh[beh$cond == 'HighLarge',]
beh_pwant_hs <- beh[beh$cond == 'HighSmall',]
beh_pwant_ll <- beh[beh$cond == 'LowLarge',]
beh_pwant_ls <- beh[beh$cond == 'LowSmall',]

#create new data sets with person(i)-mean (pm) values for each condition
hl_imeans <- ddply(beh_pwant_hl, "id", summarize,
                       p_want_hl_pm = mean(p_want_of_resp, na.rm=TRUE))

hs_imeans <- ddply(beh_pwant_hs, "id", summarize,
                       p_want_hs_pm = mean(p_want_of_resp, na.rm=TRUE))

ll_imeans <- ddply(beh_pwant_ll, "id", summarize,
                       p_want_ll_pm = mean(p_want_of_resp, na.rm=TRUE))

ls_imeans <- ddply(beh_pwant_ls, "id", summarize,
                       p_want_ls_pm = mean(p_want_of_resp, na.rm=TRUE))

# create wide trait data set -- will have the average wanting for each person, by condition (1 per column)
beh_pwant_trait <- merge(hl_imeans, hs_imeans, by="id")
beh_pwant_trait <- merge(beh_pwant_trait, ll_imeans, by="id")
beh_pwant_trait <- merge(beh_pwant_trait, ls_imeans, by="id")

# make long
beh_pwant_trait_long <- melt(beh_pwant_trait, id.vars=c("id"))

# #Merge individual means with subset dataframes
# beh_pwant_hl <- merge(beh_pwant_hl, hl_imeans, by="id")
# beh_pwant_hs <- merge(beh_pwant_hs, hs_imeans, by="id")
# beh_pwant_ll <- merge(beh_pwant_ll, ll_imeans, by="id")
# beh_pwant_ls <- merge(beh_pwant_ls, ls_imeans, by="id")
# 
# # within - person center variables
# beh_pwant_hl$hl_wpc <- NA
# beh_pwant_hl$hl_wpc = beh_pwant_hl$p_want_of_resp - beh_pwant_hl$p_want_hl_pm
# 
# beh_pwant_hs$hs_wpc <- NA
# beh_pwant_hs$hs_wpc = beh_pwant_hs$p_want_of_resp - beh_pwant_hs$p_want_hs_pm
# 
# beh_pwant_ll$hl_wpc <- NA
# beh_pwant_ll$hl_wpc = beh_pwant_ll$p_want_of_resp - beh_pwant_ll$p_want_ll_pm
# 
# beh_pwant_ls$ls_wpc <- NA
# beh_pwant_ls$ls_wpc = beh_pwant_ls$p_want_of_resp - beh_pwant_ls$p_want_ls_pm
# 
# 
# #grand mean center p_want_of_resp (trait)
# beh_pwant_hl$hl_gmc <- NA
# beh_pwant_hl$hl_gmc = beh_pwant_hl$p_want_hl_pm - mean(beh_pwant_hl$p_want_of_resp, na.rm = T)
# 
# beh_pwant_hs$hs_gmc <- NA
# beh_pwant_hs$hs_gmc = beh_pwant_hs$p_want_hs_pm - mean(beh_pwant_hs$p_want_of_resp, na.rm = T)
# 
# beh_pwant_ll$ll_gmc <- NA
# beh_pwant_ll$ll_gmc = beh_pwant_ll$p_want_ll_pm - mean(beh_pwant_ll$p_want_of_resp, na.rm = T)
# 
# beh_pwant_ls$ls_gmc <- NA
# beh_pwant_ls$ls_gmc = beh_pwant_ls$p_want_ls_pm - mean(beh_pwant_ls$p_want_of_resp, na.rm = T)

```

# Descriptive stats and plots
```{r avg p_want: descriptives and plot, include=TRUE}

# get descriptive stats for average (trait) wanting scores
## average wanting scores reflect each subjects percent wanting for each condition, averaged across all runs
## sd reflects between-person variability in trait wanting (i.e., the dispersion of each individual’s mean around the overall sample average (grand mean))

describe(beh_pwant_trait)

# Function to produce summary statistics (mean and +/- sd)
data_summary <- function(x) {
   m <- mean(x)
   m_minusSD <- m-sd(x)
   m_plusSD <- m+sd(x)
   return(c(y=m,ymin=m_minusSD,ymax=m_plusSD))
}

# violin plot with mean (dot) and +/- 1SD bar
ggplot(beh_pwant_trait_long, aes(x=variable, y=value)) + 
    geom_violin(trim=FALSE) + stat_summary(fun.data=data_summary)

# violin plot with dot plot
ggplot(beh_pwant_trait_long, aes(x=variable, y=value)) + 
    geom_violin(trim=FALSE) + 
    geom_dotplot(binaxis='y', stackdir='center', dotsize=1)

```

```{r avg liking and fullness: descriptives and plot, include=TRUE}
# descriptive stats 
like_long %>%
  group_by(portion_size, type) %>%
  get_summary_stats(avg_liking, type = "common")

full_long %>%
  group_by(portion_size, type) %>%
  get_summary_stats(avg_fullness, type = "common")

# boxplot: average liking
ggplot(like_long, aes(x=portion_size, y=avg_liking, fill=type)) +
  geom_boxplot() 

# boxplot: average fullness (food conditions only)
ggplot(full_long, aes(x=portion_size, y=avg_fullness, fill=type)) +
  geom_boxplot() 

# violin plot: average liking
ggplot(like_long, aes(x = condition, y = avg_liking, fill = type)) + 
  geom_violin(aes(fill = type), trim = FALSE) +
  #geom_boxplot(width = 0.1) +
  theme_classic() +
  geom_dotplot(binaxis = "y",
            stackdir = "center",
            dotsize = 0.5) +
  theme(legend.position = "none")

# violin plot: average fullness (food conditions only)
ggplot(full_long, aes(x = condition, y = avg_fullness)) + 
  geom_violin(aes(fill = portion_size), trim = FALSE) +
  #geom_boxplot(width = 0.1) +
  theme_classic() +
  geom_dotplot(binaxis = "y",
            stackdir = "center",
            dotsize = 0.5) +
  theme(legend.position = "none")

```

```{r within-person p_want descriptives, include=TRUE}

# Within-person variability: the dispersion of each individual’s score around person’s own average (person mean)


# for each condition, fit empty model predicting p_want_of_resp from random intercept
emptymodel_hl <- lmer(formula = p_want_of_resp ~ 1 + (1|id), 
              data=beh_pwant_hl,
              na.action=na.exclude)

emptymodel_hs <- lmer(formula = p_want_of_resp ~ 1 + (1|id), 
              data=beh_pwant_hs,
              na.action=na.exclude)

emptymodel_ll <- lmer(formula = p_want_of_resp ~ 1 + (1|id), 
              data=beh_pwant_ll,
              na.action=na.exclude)

emptymodel_ls <- lmer(formula = p_want_of_resp ~ 1 + (1|id), 
              data=beh_pwant_ls,
              na.action=na.exclude)

summary(emptymodel_hl)
summary(emptymodel_hs)
summary(emptymodel_ll)
summary(emptymodel_ls)

# use intecepts and residuals from empty model to assess within-person sd -- but how??? MVM class 6
randeff_hl <- as.data.frame(VarCorr(emptymodel_hl)) # extract variance and sd components 
int_hl <- randeff_hl[1,4] # extract intercept
residual_hl <- randeff_hl[2,4] # extract residual
residual_sd_hl <- randeff_hl[2,5] # extract residual sd


# ICC : the % of total variability that is between-person (percent of variabilty due to differences between people)
#ICC_between <- RandomEffects[1,4]/(RandomEffects[1,4]+RandomEffects[2,4]) 
ICC_between_hl <- int_hl / (int_hl + residual_hl)

```

```{r plot behavior by run/block procedure}
beh$run <- as.factor(beh$run)

#### wanting by run ####
# facet box plots -- plot wanting for each condition across runs
want_byrun <- ggplot(beh, aes(x=run, y=p_want_of_resp, fill=cond)) + 
    geom_boxplot() +
    facet_wrap(~cond)
want_byrun

#### wanting by block procedure ####
# facet box plots -- plot wanting for each condition across block_proc (order of block_proc differered between versions A and B)
want_byproc <- ggplot(beh, aes(x=block_proc, y=p_want_of_resp, fill=cond)) + 
    geom_boxplot() +
    facet_wrap(~cond)
want_byproc

#### liking by block procedure ####
# subset liking
like_byproc <- avg_ratings[,grep("id|^like_a|^like_b|^like_c|^like_d", colnames(avg_ratings))]

# wide to long
like_byproc_long <- gather(data = like_byproc, key = block_proc, like_a1:like_d5,value = avg_like)

# remove "like_" from 
like_byproc_long$block_proc<-gsub("like_","",as.character(like_byproc_long$block_proc))

# split block_proc into 2 columns (split on first character of block_proc)
like_byproc_long <- like_byproc_long %>% separate(block_proc, c("cond", "proc"), sep = 1)

# facet box plots -- plot liking for each food condition across block_proc
like_byproc <- ggplot(like_byproc_long, aes(x=proc, y=avg_like, fill=cond)) + 
    geom_boxplot() +
    facet_wrap(~cond)
like_byproc

#### fullness by block procedure ####
full_byproc <- avg_ratings[,grep("id|^full_a|^full_b|^full_c|^full_d", colnames(avg_ratings))]

# wide to long
full_byproc_long <- gather(data = full_byproc, key = block_proc, full_a1:full_d5,value = avg_full)

# remove "full_" from 
full_byproc_long$block_proc<-gsub("full_","",as.character(full_byproc_long$block_proc))

# split block_proc into 2 columns (split on first character of block_proc)
full_byproc_long <- full_byproc_long %>% separate(block_proc, c("cond", "proc"), sep = 1)

# facet box plots -- plot liking for each food condition across block_proc
full_byproc <- ggplot(full_byproc_long, aes(x=proc, y=avg_full, fill=cond)) + 
    geom_boxplot() +
    facet_wrap(~cond)
full_byproc
```

```{r Difference score violin plots}

#### large - small fullness ratings #### 

# plot
ggplot(full_diff_ratings_long, aes(x = condition, y = LvS_fullness)) + 
  geom_violin(aes(fill = condition), trim = FALSE) +
  geom_boxplot(width = 0.1) +
  theme_classic() +
  geom_dotplot(binaxis = "y",
            stackdir = "center",
            dotsize = 0.5) +
  theme(legend.position = "none")

```

# Analyses
```{r p_want correlations between conditions}

beh_1 <- beh[beh$id == "1", c("id", "cond", "p_want_of_resp", "run")]
beh_12 <- beh[(beh$id == "1" | beh$id == "2"), c("id", "cond", "p_want_of_resp", "run")]

beh_HL <- beh_12[beh_12$cond == "HighLarge", c("id", "cond", "p_want_of_resp", "run")]


# reshape run 1
beh_p_want_r1 <- beh[beh$run == "1", c("id", "cond", "p_want_of_resp")]
wide_r1 <- reshape(beh_p_want_r1, idvar = "id", timevar = "cond", direction = "wide")
wide_r1$run <- "1"

# reshape run 2
beh_p_want_r2 <- beh[beh$run == "2", c("id", "cond", "p_want_of_resp")]
wide_r2 <- reshape(beh_p_want_r2, idvar = "id", timevar = "cond", direction = "wide")
wide_r2$run <- "2"

beh_p_want_r3 <- beh[beh$run == "3", c("id", "cond", "p_want_of_resp")]
wide_r3 <- reshape(beh_p_want_r3, idvar = "id", timevar = "cond", direction = "wide")
wide_r3$run <- "3"

beh_p_want_r4 <- beh[beh$run == "4", c("id", "cond", "p_want_of_resp")]
wide_r4 <- reshape(beh_p_want_r4, idvar = "id", timevar = "cond", direction = "wide")
wide_r4$run <- "4"

beh_p_want_r5 <- beh[beh$run == "5", c("id", "cond", "p_want_of_resp")]
wide_r5 <- reshape(beh_p_want_r5, idvar = "id", timevar = "cond", direction = "wide")
wide_r5$run <- "5"

#concat

wider <- rbind(wide_r1, wide_r2, wide_r3, wide_r4, wide_r5)

cor.test(wide_r1$p_want_of_resp.HighSmall, wide_r1$p_want_of_resp.HighLarge)
cor.test(wide_r1$p_want_of_resp.LowSmall, wide_r1$p_want_of_resp.LowLarge)
cor.test(wide_r1$p_want_of_resp.OfficeSmall, wide_r1$p_want_of_resp.OfficeLarge)


ggplot(data = beh) +
  geom_line(aes(x = run, y = p_want_of_resp, group = cond, col = cond))

# for 1 sub
ggplot(beh_1, aes(x = run, y = p_want_of_resp, color = cond)) +
  geom_line(data = beh_1) + position_jitter(height = .2)

ggplot(beh_12, aes(x = run, y = p_want_of_resp, color = cond)) +
  geom_line(data = beh) + geom_line(aes(group = id))

ggplot(beh_HL, aes(x = run, y = p_want_of_resp, color = as.factor(id))) + 
  geom_line(data = beh_HL) + geom_line(aes(group = id))



```

``` {r p_want analyses - all conditions}

# remove NAs
beh_clean <- beh[!is.na(beh$p_want_of_resp),]

# portion size (large, small) x cue type (high, low, office) mixed model
p_want_mixed_all = lmer(p_want_of_resp ~ portion_size*cue_type + run + (1 | id), data = beh_clean)
anova(p_want_mixed_all)

# get predicted response after adjusting for run
beh_clean$predict_p_want <- predict(p_want_mixed_all, type="response")

#plot with ggplot
ggplot(data=beh_clean, aes(x=cue_type, y=predict_p_want, fill=portion_size)) +
  geom_bar(stat="identity", position=position_dodge())+
  scale_fill_brewer(palette="Paired")+
  theme_minimal()

# violin plot 
plot2 <- ggplot(beh_clean, aes(x=cue_type, y=predict_p_want, fill = portion_size)) +
  geom_violin(trim=FALSE)+
 # geom_signif(stat = "identity", inherit.aes = FALSE,
   #            data = data.frame(x = c(1.7, 0.7, 2.7), xend = c(3.3, 3.3, 3.3), y = c(105, 110, 85),  annotation = c("***", " ***", "*")),
  #             aes(x = x, xend = xend, y = y, yend = y, annotation = annotation)) +
  geom_boxplot(aes(group = interaction(cue_type, portion_size)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(title="Percent want",
       x="cue_type",
       y = "p_want") +
 # theme_pubr(base_size = 16) +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title = element_blank())

# barplot with alaina's function
ps_by_type <- data.frame(beh_clean$portion_size, beh_clean$cue_type)
mean_cond = means.function.na(beh_clean, beh_clean$p_want_of_resp, ps_by_type) # get mean ps and ed
se_cond = se.function.na(beh_clean, beh_clean$p_want_of_resp, ps_by_type)

beh_clean$portion_size <- as.factor(beh_clean$portion_size)
bar_graph.se(means = mean_cond, er = se_cond, xlab = "", ylab = "", ymax = 1, ymin = 0, group = beh_clean$portion_size)

```

```{r p_want analyses - food only}

# subset food conditions only
beh_food_NAs <- beh[beh$cue_type == "HighED" | beh$cue_type == "LowED",]

# remove NAs
beh_food <- beh_food_NAs[!is.na(beh_food_NAs$p_want_of_resp),]

# portion size (large, small) x food-cue type (high, low)
p_want_mixed = lmer(p_want_of_resp ~ portion_size*cue_type + run + (1 | id), data = beh_food)
anova(p_want_mixed)

# get predicted response after adjusting for run
beh_food$predict_p_want <- predict(p_want_mixed, type="response")

#plot with ggplot
ggplot(data=beh_food, aes(x=cue_type, y=predict_p_want, fill=portion_size)) +
  geom_bar(stat="identity", position=position_dodge())+
  scale_fill_brewer(palette="Paired")+
  theme_minimal()

# violin plot 
plot <- ggplot(beh_food, aes(x=cue_type, y=predict_p_want, fill = portion_size)) +
  geom_violin(trim=FALSE)+
 # geom_signif(stat = "identity", inherit.aes = FALSE,
   #            data = data.frame(x = c(1.7, 0.7, 2.7), xend = c(3.3, 3.3, 3.3), y = c(105, 110, 85),  annotation = c("***", " ***", "*")),
  #             aes(x = x, xend = xend, y = y, yend = y, annotation = annotation)) +
  geom_boxplot(aes(group = interaction(cue_type, portion_size)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(title="N-Back Task",
       x="cue_type",
       y = "p_want") +
 # theme_pubr(base_size = 16) +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title = element_blank())

# barplot with alaina's function
ps_by_ed <- data.frame(beh_food$portion_size, beh_food$cue_type)
mean_cond = means.function.na(beh_food, beh_food$p_want_of_resp, ps_by_ed) # get mean ps and ed
se_cond = se.function.na(beh_food, beh_food$p_want_of_resp, ps_by_ed)

beh_food$portion_size <- as.factor(beh_food$portion_size)
bar_graph.se(means = mean_cond, er = se_cond, xlab = "", ylab = "", ymax = 1, ymin = 0, group = beh_food$portion_size)

```

``` {r post-scan rating analyses}

# subject food only
like_long_food <- like_long[like_long$type != 'Office', ]

####  repeated measures anovas ####
# PS (Large, Small) x Type (High, Low, Office) on liking
liking_all.aov <- anova_test(
  data = like_long, dv = avg_liking, wid = id,
  within = c(type, portion_size)
  )
get_anova_table(liking.aov)

# PS (Large, Small) x ED (High, Low) on liking
liking_food.aov <- anova_test(
  data = like_long, dv = avg_liking, wid = id,
  within = c(type, portion_size)
  )
get_anova_table(liking_food.aov)

# PS (Large, Small) x ED (High, Low) on percieved fullness
fullness.aov <- anova_test(
  data = full_long, dv = avg_fullness, wid = id,
  within = c(type, portion_size)
  )
get_anova_table(fullness.aov)

# correlation between difference scores

cor.test(analyzed_df$full_LvS_overall, analyzed_df$like_LvS_overall, use = "complete.obs")

cor.test(analyzed_df$full_HvL_overall, analyzed_df$like_HvL_overall, use = "complete.obs")
# the more full a child reports for high vs. low ED foods, the more they report liking high vs. low ED foods

```
