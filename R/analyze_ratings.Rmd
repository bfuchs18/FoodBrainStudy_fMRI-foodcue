---
title: "post-scan rating analyses"
author: "baf44"
date: "1/23/2023"
output: html_document
editor_options: 
  chunk_output_type: console
---

Code to plot and analyze liking and fullness ratings

This code uses the following derivative files:

(1) 
(2) 

# Setup

```{r imports, include=FALSE}
library(lme4)
library(lmerTest) # need this to get p-values with anova()
library(plyr)
library(maditr)
library(ggplot2)
library(rstatix)
library(dplyr)
library(psych)
library(emmeans)
library(stringr)
library(ggsignif)

#### import BIDS derivatives to use in analyses ####

# import behavioral data
image_ratings <- read.csv("data/derivatives_R/fmri_image_ratings.csv")

# import index file that specifies children included in analyses
index_wide <- read.table("BIDS//derivatives/analyses/foodcue-paper1/level2/index_all_fd-0.9_b20_3runs.txt", quote="\"", comment.char="")
index <- as.data.frame(t(index_wide)) # transpose index_wide to long dataframes
names(index) <- "id" # add column name

#censor sum database
censor_sum <- read.delim("BIDS/derivatives/preprocessed/fmriprep/task-foodcue_byrun-censorsummary_fd-0.9.tsv")
names(censor_sum)[names(censor_sum) == 'sub'] <- 'id'

```

# Prepare post-scanner ratings
```{r compute avg liking and fullness ratings}
# Conditions:
# A = HighLarge
# B = HighSmall
# C = LowLarge
# D = LowSmall
# E = OfficeLarge
# F = OfficeSmall

#### compute average liking ratings  ####
# note: in grep, ^ indicates the start of the string, $ indicates the end, .+ gets everything in between

# for each condition overall
# image_ratings$like_HighLarge <- rowMeans(image_ratings[grep('^mrivas_a.+like$', names(image_ratings))])
# image_ratings$like_HighSmall <- rowMeans(image_ratings[grep('^mrivas_b.+like$', names(image_ratings))])
# image_ratings$like_LowLarge <- rowMeans(image_ratings[grep('^mrivas_c.+like$', names(image_ratings))])
# image_ratings$like_LowSmall <- rowMeans(image_ratings[grep('^mrivas_d.+like$', names(image_ratings))])
# image_ratings$like_OfficeLarge <- rowMeans(image_ratings[grep('^mrivas_e.+like$', names(image_ratings))])
# image_ratings$like_OfficeSmall <- rowMeans(image_ratings[grep('^mrivas_f.+like$', names(image_ratings))])

# for each block procedure 
image_ratings$like_a1 <- rowMeans(image_ratings[grep('^mrivas_a1.+like$', names(image_ratings))])
image_ratings$like_a2 <- rowMeans(image_ratings[grep('^mrivas_a2.+like$', names(image_ratings))])
image_ratings$like_a3 <- rowMeans(image_ratings[grep('^mrivas_a3.+like$', names(image_ratings))])
image_ratings$like_a4 <- rowMeans(image_ratings[grep('^mrivas_a4.+like$', names(image_ratings))])
image_ratings$like_a5 <- rowMeans(image_ratings[grep('^mrivas_a5.+like$', names(image_ratings))])

image_ratings$like_b1 <- rowMeans(image_ratings[grep('^mrivas_b1.+like$', names(image_ratings))])
image_ratings$like_b2 <- rowMeans(image_ratings[grep('^mrivas_b2.+like$', names(image_ratings))])
image_ratings$like_b3 <- rowMeans(image_ratings[grep('^mrivas_b3.+like$', names(image_ratings))])
image_ratings$like_b4 <- rowMeans(image_ratings[grep('^mrivas_b4.+like$', names(image_ratings))])
image_ratings$like_b5 <- rowMeans(image_ratings[grep('^mrivas_b5.+like$', names(image_ratings))])

image_ratings$like_c1 <- rowMeans(image_ratings[grep('^mrivas_c1.+like$', names(image_ratings))])
image_ratings$like_c2 <- rowMeans(image_ratings[grep('^mrivas_c2.+like$', names(image_ratings))])
image_ratings$like_c3 <- rowMeans(image_ratings[grep('^mrivas_c3.+like$', names(image_ratings))])
image_ratings$like_c4 <- rowMeans(image_ratings[grep('^mrivas_c4.+like$', names(image_ratings))])
image_ratings$like_c5 <- rowMeans(image_ratings[grep('^mrivas_c5.+like$', names(image_ratings))])

image_ratings$like_d1 <- rowMeans(image_ratings[grep('^mrivas_d1.+like$', names(image_ratings))])
image_ratings$like_d2 <- rowMeans(image_ratings[grep('^mrivas_d2.+like$', names(image_ratings))])
image_ratings$like_d3 <- rowMeans(image_ratings[grep('^mrivas_d3.+like$', names(image_ratings))])
image_ratings$like_d4 <- rowMeans(image_ratings[grep('^mrivas_d4.+like$', names(image_ratings))])
image_ratings$like_d5 <- rowMeans(image_ratings[grep('^mrivas_d5.+like$', names(image_ratings))])

image_ratings$like_e1 <- rowMeans(image_ratings[grep('^mrivas_e1.+like$', names(image_ratings))])
image_ratings$like_e2 <- rowMeans(image_ratings[grep('^mrivas_e2.+like$', names(image_ratings))])
image_ratings$like_e3 <- rowMeans(image_ratings[grep('^mrivas_e3.+like$', names(image_ratings))])
image_ratings$like_e4 <- rowMeans(image_ratings[grep('^mrivas_e4.+like$', names(image_ratings))])
image_ratings$like_e5 <- rowMeans(image_ratings[grep('^mrivas_e5.+like$', names(image_ratings))])

image_ratings$like_f1 <- rowMeans(image_ratings[grep('^mrivas_f1.+like$', names(image_ratings))])
image_ratings$like_f2 <- rowMeans(image_ratings[grep('^mrivas_f2.+like$', names(image_ratings))])
image_ratings$like_f3 <- rowMeans(image_ratings[grep('^mrivas_f3.+like$', names(image_ratings))])
image_ratings$like_f4 <- rowMeans(image_ratings[grep('^mrivas_f4.+like$', names(image_ratings))])
image_ratings$like_f5 <- rowMeans(image_ratings[grep('^mrivas_f5.+like$', names(image_ratings))])
# 
# # across conditions
# image_ratings$like_HighED <- rowMeans(image_ratings[grep('^mrivas_a.+like$|mrivas_b.+like$', names(image_ratings))])
# image_ratings$like_LowED <- rowMeans(image_ratings[grep('^mrivas_c.+like$|mrivas_d.+like$', names(image_ratings))])
# image_ratings$like_LargePS <- rowMeans(image_ratings[grep('^mrivas_a.+like$|mrivas_c.+like$', names(image_ratings))])
# image_ratings$like_SmallPS <- rowMeans(image_ratings[grep('^mrivas_b.+like$|mrivas_d.+like$', names(image_ratings))])
# image_ratings$like_Office <- rowMeans(image_ratings[grep('^mrivas_e.+like$|mrivas_f.+like$', names(image_ratings))])
# image_ratings$like_food <- rowMeans(image_ratings[grep('^mrivas_a.+like$|mrivas_b.+like$|^mrivas_c.+like$|mrivas_d.+like$', names(image_ratings))])
# 
# #### compute average fullness ratings  ####
# # for each food condition overall
# image_ratings$full_HighLarge <- rowMeans(image_ratings[grep('^mrivas_a.+full$', names(image_ratings))])
# image_ratings$full_HighSmall <- rowMeans(image_ratings[grep('^mrivas_b.+full$', names(image_ratings))])
# image_ratings$full_LowLarge <- rowMeans(image_ratings[grep('^mrivas_c.+full$', names(image_ratings))])
# image_ratings$full_LowSmall <- rowMeans(image_ratings[grep('^mrivas_d.+full$', names(image_ratings))])

# for each block procedure of the 4 food conditions (a-d)
image_ratings$full_a1 <- rowMeans(image_ratings[grep('^mrivas_a1.+full$', names(image_ratings))])
image_ratings$full_a2 <- rowMeans(image_ratings[grep('^mrivas_a2.+full$', names(image_ratings))])
image_ratings$full_a3 <- rowMeans(image_ratings[grep('^mrivas_a3.+full$', names(image_ratings))])
image_ratings$full_a4 <- rowMeans(image_ratings[grep('^mrivas_a4.+full$', names(image_ratings))])
image_ratings$full_a5 <- rowMeans(image_ratings[grep('^mrivas_a5.+full$', names(image_ratings))])

image_ratings$full_b1 <- rowMeans(image_ratings[grep('^mrivas_b1.+full$', names(image_ratings))])
image_ratings$full_b2 <- rowMeans(image_ratings[grep('^mrivas_b2.+full$', names(image_ratings))])
image_ratings$full_b3 <- rowMeans(image_ratings[grep('^mrivas_b3.+full$', names(image_ratings))])
image_ratings$full_b4 <- rowMeans(image_ratings[grep('^mrivas_b4.+full$', names(image_ratings))])
image_ratings$full_b5 <- rowMeans(image_ratings[grep('^mrivas_b5.+full$', names(image_ratings))])

image_ratings$full_c1 <- rowMeans(image_ratings[grep('^mrivas_c1.+full$', names(image_ratings))])
image_ratings$full_c2 <- rowMeans(image_ratings[grep('^mrivas_c2.+full$', names(image_ratings))])
image_ratings$full_c3 <- rowMeans(image_ratings[grep('^mrivas_c3.+full$', names(image_ratings))])
image_ratings$full_c4 <- rowMeans(image_ratings[grep('^mrivas_c4.+full$', names(image_ratings))])
image_ratings$full_c5 <- rowMeans(image_ratings[grep('^mrivas_c5.+full$', names(image_ratings))])

image_ratings$full_d1 <- rowMeans(image_ratings[grep('^mrivas_d1.+full$', names(image_ratings))])
image_ratings$full_d2 <- rowMeans(image_ratings[grep('^mrivas_d2.+full$', names(image_ratings))])
image_ratings$full_d3 <- rowMeans(image_ratings[grep('^mrivas_d3.+full$', names(image_ratings))])
image_ratings$full_d4 <- rowMeans(image_ratings[grep('^mrivas_d4.+full$', names(image_ratings))])
image_ratings$full_d5 <- rowMeans(image_ratings[grep('^mrivas_d5.+full$', names(image_ratings))])

# across conditions
# image_ratings$full_LargePS <- rowMeans(image_ratings[grep('^mrivas_a.+full$|mrivas_c.+full$', names(image_ratings))])
# image_ratings$full_SmallPS <- rowMeans(image_ratings[grep('^mrivas_b.+full$|mrivas_d.+full$', names(image_ratings))])
# image_ratings$full_HighED <- rowMeans(image_ratings[grep('^mrivas_a.+full$|mrivas_b.+full$', names(image_ratings))])
# image_ratings$full_LowED <- rowMeans(image_ratings[grep('^mrivas_c.+full$|mrivas_d.+full$', names(image_ratings))])

#subset liking and fullness data
avg_ratings_all <- image_ratings[,grep("id|^like|^full", colnames(image_ratings))]

```

```{r subset to children included for non-parametric fmri analyses}
avg_ratings <- setDT(avg_ratings_all)[id %chin% index$id]
```

```{r long liking and fullness datasets by block}

# get list of columns that start with "like_" and have 2 characters after 
byblock_like_columns <- grep("^like_[[:alnum:]]{2}$", names(avg_ratings), value = TRUE)

# get list of columns that start with "like_" and have 2 characters after 
byblock_fullness_columns <- grep("^full_[[:alnum:]]{2}$", names(avg_ratings), value = TRUE)

# wide to long -- liking ratings 
byblock_like_long <- reshape2::melt(avg_ratings,
        # ID variables - all the variables to keep but not split apart on
    id.vars=c("id"),
        # The source columns
    measure.vars=byblock_like_columns,
        # Name of the destination column that will identify the original
        # column that the measurement came from
    variable.name="block_proc",
    value.name="avg_liking"
)

# wide to long -- fullness ratings
byblock_full_long <- reshape2::melt(avg_ratings,
        # ID variables - all the variables to keep but not split apart on
    id.vars=c("id"),
        # The source columns
    measure.vars=byblock_fullness_columns,
        # Name of the destination column that will identify the original
        # column that the measurement came from
    variable.name="block_proc",
    value.name="avg_fullness"
)

# cond column -- to match the way conditions are labeled for onset files
byblock_like_long <- byblock_like_long %>%
  mutate(cond = case_when(
    grepl("_a", block_proc) ~ "HighLarge",
    grepl("_b", block_proc) ~ "HighSmall",
    grepl("_c", block_proc) ~ "LowLarge",
    grepl("_d", block_proc) ~ "LowSmall",
    grepl("_e", block_proc) ~ "OfficeLarge",
    grepl("_f", block_proc) ~ "OfficeSmall",
    TRUE ~ ""  # Default value if none of the conditions are met
  )) 

byblock_full_long <- byblock_full_long %>%
  mutate(cond = case_when(
    grepl("_a", block_proc) ~ "HighLarge",
    grepl("_b", block_proc) ~ "HighSmall",
    grepl("_c", block_proc) ~ "LowLarge",
    grepl("_d", block_proc) ~ "LowSmall",
    TRUE ~ ""  # Default value if none of the conditions are met
  )) 

# Make portion size and category columns
byblock_like_long$category <- ifelse(grepl("High", byblock_like_long$cond), "HighED", 
                                ifelse(grepl("Low", byblock_like_long$cond), "LowED", "Office"))

byblock_like_long$cuetype <- ifelse(grepl("High", byblock_like_long$cond), "food", 
                                ifelse(grepl("Low", byblock_like_long$cond), "food", "office"))

byblock_like_long$portion <- ifelse(grepl("Large", byblock_like_long$cond), "Large", "Small")

byblock_full_long$category <- ifelse(grepl("High", byblock_full_long$cond), "HighED", "LowED")

byblock_full_long$portion <- ifelse(grepl("Large", byblock_full_long$cond), "Large", "Small")

# add mri_task version
byblock_like_long <- merge(byblock_like_long, image_ratings[, c("id", "mri_version")], by="id")
byblock_full_long <- merge(byblock_full_long, image_ratings[, c("id", "mri_version")], by="id")

# make run column
## proc order by mri_version
## version 1 (A) : 1, 3, 4, 5, 2
## version 2 (B) : 2, 5, 4, 3, 1

byblock_like_long$mri_version <- as.character(byblock_like_long$mri_version)
byblock_like_long <- byblock_like_long %>%
  mutate(run = case_when(
    mri_version == "1" & grepl("1", block_proc) ~ "1",
    mri_version == "1" & grepl("2", block_proc) ~ "5",
    mri_version == "1" & grepl("3", block_proc) ~ "2",
    mri_version == "1" & grepl("4", block_proc) ~ "3",
    mri_version == "1" & grepl("5", block_proc) ~ "4",
    mri_version == "2" & grepl("1", block_proc) ~ "5",
    mri_version == "2" & grepl("2", block_proc) ~ "1",
    mri_version == "2" & grepl("3", block_proc) ~ "4",
    mri_version == "2" & grepl("4", block_proc) ~ "3",
    mri_version == "2" & grepl("5", block_proc) ~ "2",
    TRUE ~ ""  # Default value if none of the conditions are met
  ))

byblock_full_long$mri_version <- as.character(byblock_full_long$mri_version)
byblock_full_long <- byblock_full_long %>%
  mutate(run = case_when(
    mri_version == "1" & grepl("1", block_proc) ~ "1",
    mri_version == "1" & grepl("2", block_proc) ~ "5",
    mri_version == "1" & grepl("3", block_proc) ~ "2",
    mri_version == "1" & grepl("4", block_proc) ~ "3",
    mri_version == "1" & grepl("5", block_proc) ~ "4",
    mri_version == "2" & grepl("1", block_proc) ~ "5",
    mri_version == "2" & grepl("2", block_proc) ~ "1",
    mri_version == "2" & grepl("3", block_proc) ~ "4",
    mri_version == "2" & grepl("4", block_proc) ~ "3",
    mri_version == "2" & grepl("5", block_proc) ~ "2",
    TRUE ~ ""  # Default value if none of the conditions are met
  ))
```

Export for use in parametric analyses
``` {r export}

write.csv(byblock_like_long, 'BIDS/derivatives/analyses/foodcue-paper1/R/liking_ratings_byblock.csv', row.names = FALSE)
write.csv(byblock_full_long, 'BIDS/derivatives/analyses/foodcue-paper1/R/fullness_ratings_byblock.csv', row.names = FALSE)

```

####  Prepare for parametric analyses #### 

The follow chunk is used to determine what subjects to exclude from parametric analyses

Subjects will be excluded if:
(1) they are missing ratings (fullness, liking) for any block
(2) they do not have enough variability in rating to be included in analyses (must have >1 unique value)

```{r identify subs to exclude}

#### Identify subs with missing ratings for any block ####

# make list subjects with missing fullness data for any block
pm_missing_fullness <- unique(byblock_full_long[is.na(byblock_full_long$avg_fullness),"id"])
pm_missing_fullness # 5 109

# make list subjects with missing behavior for any block
pm_missing_liking <- unique(byblock_like_long[is.na(byblock_like_long$avg_liking),"id"])
pm_missing_liking # 5 109

# count number of subjects with missing data
nrow(pm_missing_fullness) # N = 2
nrow(pm_missing_liking) # N = 2

#### clean data base ####

# remove subjects with missing data
pm_full_temp <- byblock_full_long[ ! byblock_full_long$id %in% pm_missing_fullness, ]
pm_like_temp <- byblock_like_long[ ! byblock_like_long$id %in% pm_missing_liking, ]

# remove runs excluded for motion
censor_sum_subset <- censor_sum[,c("id", "run", "p_censor_interest")]

pm_full_clean <- merge(x=pm_full_temp,y=censor_sum_subset, 
             by=c("id","run"))
pm_full_clean <-pm_full_clean[!(pm_full_clean$p_censor_interest>20),]

pm_like_clean <- merge(x=pm_like_temp,y=censor_sum_subset, 
             by=c("id","run"))
pm_like_clean <-pm_like_clean[!(pm_like_clean$p_censor_interest>20),]

#### Identify subs with  no variability ####

# count number of distinct fullness values by id and ED condition (high, low)
distinct_full_byED <- pm_full_clean %>% group_by(id, category) %>% dplyr::summarize(distinct = n_distinct(avg_fullness))

# count number of distinct fullness values by id and portion condition (large, small)
distinct_full_byPS <- pm_full_clean %>% group_by(id, portion) %>% dplyr::summarize(distinct = n_distinct(avg_fullness))

# count number of distinct liking values by id and ED condition (high, low)
distinct_like_byED <- pm_like_clean %>% filter(cuetype != "office") %>% 
                      group_by(id, category) %>% dplyr::summarize(distinct = n_distinct(avg_liking))

# count number of distinct liking values by id and food PS condition (large, small)
distinct_like_byPS <- pm_like_clean %>% filter(cuetype != "office") %>% 
                      group_by(id, portion) %>% dplyr::summarize(distinct = n_distinct(avg_liking))

# count number of distinct liking values by id and cue type (large, small)
distinct_like_byCue <- pm_like_clean %>% group_by(id, cuetype) %>% dplyr::summarize(distinct = n_distinct(avg_liking))

# Count subs with no variability in fullness (distinct==1) in at least 1 condition when assessing by ED
novar_full_byED <- distinct_full_byED[(distinct_full_byED$distinct==1),] %>%
  dplyr::summarize(distinct = n_distinct(id))
nrow(novar_full_byED) # N = 0

# Count subs with no variability in fullness (distinct==1) in at least 1 condition when assessing by PS
novar_full_byPS <- distinct_full_byPS[(distinct_full_byPS$distinct==1),] %>%
  dplyr::summarize(distinct = n_distinct(id))
nrow(novar_full_byPS) # N = 0

# Count subs with no variability in liking (distinct==1) in at least 1 condition when assessing by ED
novar_like_byED <- distinct_like_byED[(distinct_like_byED$distinct==1),]
nrow(novar_like_byED) # N = 0

# Count subs with no variability in liking (distinct==1) in at least 1 condition when assessing by PS
novar_like_byPS <- distinct_like_byPS[(distinct_like_byPS$distinct==1),]
nrow(novar_like_byED) # N = 0

# Count subs with no variability in liking (distinct==1) in at least 1 condition when assessing by cue type
novar_like_byCue <- distinct_like_byCue[(distinct_like_byCue$distinct==1),]
nrow(novar_like_byCue) # N = 1
novar_like_byCue$id # 73 ## ID 73 rated 0 for all office supplies


```

```{r count subs included in parametric analyses analyses}

#### count subs included in parametric analyses analyses ####
n_distinct(distinct_full_byED$id)
n_distinct(distinct_full_byPS$id)
n_distinct(distinct_like_byED$id)
n_distinct(distinct_like_byPS$id)
n_distinct(distinct_like_byCue[!(distinct_like_byCue$id==73),]$id) # remove  73 -- no variation in rating for office supplies

```


#### Behavioral analyses ####

The following code analyses liking and fullness by cue type/ED and amount and generates corresponding plots.
Ratings are assessed for all subjects included in non-parametric analyses (n=61).

# should run be numeric or categorical?

``` {r liking analyses}

# create food-only dataframe by removing office conditions
byblock_like_long_food<-byblock_like_long[!(byblock_like_long$ED=="Office"),]

# remove NAs -- not needed to run analyses, but helpful for predicting values to plot results
byblock_like_clean<-byblock_like_long[!is.na(byblock_like_long$avg_liking),]
byblock_like_food_clean <- byblock_like_long_food[!is.na(byblock_like_long_food$avg_liking),]


#### ANALYSES ####

# should run be numeric or categorical?

# portion size (large, small) x cue type (food, office)
liking_mixed_cuetype = lmer(avg_liking ~ portion*category + as.numeric(run) + (1 | id), data = byblock_like_clean)
anova(liking_mixed_cuetype)

# portion size (large, small) x food-cue type (high, low)
liking_mixed_ED = lmer(avg_liking ~ portion*ED + as.numeric(run) + (1 | id), data = byblock_like_food_clean)
anova(liking_mixed_ED)

# get means and ses
emmeans(liking_mixed_cuetype, specs = pairwise ~category|portion, type = "response")
emmeans(liking_mixed_ED, specs = pairwise ~category|portion, type = "response")

```

fullness analyses
``` {r fullness analyses}
# remove NAs -- not needed to run analyses, but helpful for predicting values to plot results
byblock_full_clean<-byblock_full_long[!is.na(byblock_full_long$avg_fullness),]

# portion size (large, small) x food-cue type (high, low)
fullness_mixed_ED = lmer(avg_fullness ~ portion*category + as.numeric(run) + (1 | id), data = byblock_full_clean)
anova(fullness_mixed_ED)

emmeans(fullness_mixed_ED, specs = pairwise ~category|portion, type = "response")


```

Figure 1:
``` {r liking and fullness plots}

# get adjusted response after adjusting for covariates in model 
byblock_like_clean$predict_liking_mixed_cuetype <- predict(liking_mixed_cuetype, type="response")
byblock_like_food_clean$predict_liking_mixed_ED <- predict(liking_mixed_ED, type="response")
byblock_full_clean$predict_fullness_mixed_ED <- predict(fullness_mixed_ED, type="response")

#### VIOLIN PLOTS with ggplot####

# liking ~ amount x cue type
plot_liking_cuetype <- ggplot(byblock_like_clean, aes(x=category, y=predict_liking_mixed_cuetype, fill = portion)) +
  theme_bw() +
  geom_violin(trim=FALSE) +
  geom_signif(comparisons = list(c("food","Office")), y_position = 110, map_signif_level = TRUE) +
  geom_boxplot(aes(group = interaction(category, portion)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(x="Cue Type",
       y = "Adjusted liking") +
  theme(legend.title = element_blank()) +
  theme(axis.text=element_text(size=12, color = "black"), axis.title=element_text(size=14,face="bold")) + 
  ylim(0, 125) + 
  scale_x_discrete(labels = c("food" = "Food",
                              "Office" = "Office Supplies"))

plot_liking_cuetype

# liking ~ amount x ED
plot_liking_ED <- ggplot(byblock_like_food_clean, aes(x=ED, y=predict_liking_mixed_ED, fill = portion)) +
  theme_bw() +
  geom_violin(trim=FALSE)+
  geom_signif(comparisons = list(c("HighED","LowED")), y_position = 110,
              map_signif_level = TRUE) +
  geom_boxplot(aes(group = interaction(ED, portion)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(x="Energy Density",
       y = "Adjusted liking") +
  theme(legend.title = element_blank()) +
  theme(axis.text=element_text(size=12, color = "black"), axis.title=element_text(size=14,face="bold")) + 
  ylim(0, 125) +
  scale_x_discrete(labels = c("HighED" = "Higher",
                              "LowED" = "Lower"))

plot_liking_ED

# fullness ~ amount x ED
plot_fullness_ED <- ggplot(byblock_full_clean, aes(x=category, y=predict_fullness_mixed_ED, fill = portion)) +
  theme_bw() +
  geom_violin(trim=FALSE)+
  geom_signif(comparisons = list(c("HighED","LowED")), y_position = 110, map_signif_level = TRUE) +
  geom_boxplot(aes(group = interaction(category, portion)), fill = 'white', position = position_dodge(width = 0.9),  width = 0.1, outlier.shape = NA) +
  scale_fill_manual(values = c("lightgrey", "grey35")) +
  labs(x="Energy Density",
       y = "Adjusted anticipated fullness") +
  theme(legend.title = element_blank()) +
  theme(axis.text=element_text(size=12, color = "black"), axis.title=element_text(size=14,face="bold")) + 
  ylim(-10, 125) +
  scale_x_discrete(labels = c("HighED" = "Higher",
                              "LowED" = "Lower"))

plot_fullness_ED # need to add significance bar for portion size comparison

```
